[
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#about-ontotext",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#about-ontotext",
    "title": "Ontotext CH/DH Projects",
    "section": "1 About Ontotext",
    "text": "1 About Ontotext\n\nFounded 2000, part of Sirma Group (400 people, BSE:SKK, part of SOFIX), venture funding 2008\n65 people: 7 PhD, 30 MS, 20 BS, 6 university lecturers. Offices in Sofia, Varna, London\nCore part of Sirma Strategy 2022 with focus on cognitive computing\nWorking on: semantic technologies, semantic text analysis and machine learning\nSemantic Graph Database: Ontotext GraphDB\nSemantic data integration and building Knowledge Graphs\nSemantic text analysis: entity, concept, relation extraction, document classification\nRecommendations, sentiment analysis\nMachine learning: entity disambiguation, deep learning in graphs, etc"
  },
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#research-projects",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#research-projects",
    "title": "Ontotext CH/DH Projects",
    "section": "2 Research Projects",
    "text": "2 Research Projects"
  },
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#industries-and-clients",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#industries-and-clients",
    "title": "Ontotext CH/DH Projects",
    "section": "3 Industries and Clients",
    "text": "3 Industries and Clients\n\n80% of our sales are in the UK and US\nMedia: BBC, UK Press Association, NL Press Association (NDP)\nFinancial Info: S&P Global Platts, Euromoney, Financial Times, Nikkei\nSTEM Publishing: IET, Oxford University Press, Wiley, Elsevier, Springer Nature\nLife Science: AstraZeneca, Novartis\nGovernment: UK Parliament, The National Archives, Natural Resources Canada\nCultural Heritage and Digital Humanities (see next)"
  },
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#chdh-projects",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#chdh-projects",
    "title": "Ontotext CH/DH Projects",
    "section": "4 CH/DH Projects",
    "text": "4 CH/DH Projects\n\nResearchSpace: British Museum, Yale Center for British Art. Largest museum collection, CIDOC CRM, semantic search…\n(with Sirma Enterprise) ConservationSpace, Sirma MuseumSpace\nMedieval Cultures and Technological Resources (VCMS) COST action\nEuropeana: Creative, Food and Drink (sem app), OAI PMH, SPARQL, members council, 5 work groups, Data Quality Committee\nBulgariana national aggegator, CLADA (BG CLARIN+DARIAH)\nGetty Research Institute: vocabularies LOD\nCarnegie Hall LOD\nAmerican Art Collaborative consulting: 14 US museums integrating data using CIDOC CRM\nEuropean Holocaust Research Infrastructure: semantic archive integration. 4+4 years, heading towards ERIC\nCanadian Heritage Information Network consulting (national aggregator moving to LOD)\nWikidata: frequent contributions (authority control)\nDBpedia: contributions, association member, data quality and ontology committee"
  },
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#semantic-data-integration-1",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#semantic-data-integration-1",
    "title": "Ontotext CH/DH Projects",
    "section": "5 Semantic Data Integration (1)",
    "text": "5 Semantic Data Integration (1)\n\nWell-developed process\nBusiness case, competence questions\nDataset analysis and understanding\n\nKnowledge and exploration of useful external datasets (leverage LOD)\n\nSemantic Modeling\n\nSelection of existing ontologies\nEngineering of new ontologies (ontology creation methodologies, ontology design patterns, naming conventions)\nRDF profile/shape development (also key for validation\nURL (IRI) strategies and design"
  },
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#semantic-data-integration-2",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#semantic-data-integration-2",
    "title": "Ontotext CH/DH Projects",
    "section": "6 Semantic Data Integration (2)",
    "text": "6 Semantic Data Integration (2)\n\nModel documentation\n\nDiagrams\nDetailed ontology term description, Examples\nData provider rules\nSample queries\n\nSemantic conversion/ETL/ingestion\n\nTool selection: OntoRefine, Karma, R2RML, rdfpuml/rdf2rml, TARQL, XSPARQL, LIXR…\nMaintainability, Reproducibility/portability, Data cleansing"
  },
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#semantic-data-integration-3",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#semantic-data-integration-3",
    "title": "Ontotext CH/DH Projects",
    "section": "7 Semantic Data Integration (3)",
    "text": "7 Semantic Data Integration (3)\n\nSemantic data enrichment\n\nInference. Attributes and relations are added based on rules.\nThesaurus harmonisation\nEntity and relation extraction\nLink discovery (eg graph based ML)\nInstance matching (clustering, linking, deduplication)\nData fusion (redundant/conflicting data is deduplicated/fused)\n\nQuality Assurance\n\nData is validated with respect to model\nDeploy RDF shapes tools (SHACL or ShEx)\nData quality tracking (issue tracking system for data)"
  },
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#semantic-data-integration-4",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#semantic-data-integration-4",
    "title": "Ontotext CH/DH Projects",
    "section": "8 Semantic Data Integration (4)",
    "text": "8 Semantic Data Integration (4)\n\nData Update flows\n\nDetecting updates (push, pull/requery, update timestamps)\nUpdate impact anlaysis (eg on instance clusters, derived data)\nImplementing incremental updates (GraphDB smooth delete)\nData aggregation issues (volume)\n\nSemantic publishing and consumption\n\nSemantic publishing of: model, nomenclatures, instance data\nProper semantic resolution and Content negotiation (HTML and various RDF formats)\nServices such as SPARQL querying, autocomplete\nData service availability monitoring"
  },
  {
    "objectID": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#knowledge-graphs",
    "href": "markdown/20180601-TimeMachine-ONTO-CH/Slides.html#knowledge-graphs",
    "title": "Ontotext CH/DH Projects",
    "section": "9 Knowledge Graphs",
    "text": "9 Knowledge Graphs\n\n\n\nKnowledge Graph\nYear\nM obj\nB triples\n\n\n\n\nBritish Museum\n2013\n2\n0.92\n\n\nPolish DL\n2013\n3.1\n0.53\n\n\nEuropeana\n2014\n20.3\n3.8\n\n\nFactForge\n2006-now\n~14\n3.2\n\n\nLinkedLifeData\n2008-now\n~12\n10.2\n\n\nCompany Graph\n2017-now\n6\n3\n\n\nDun & Bradstreet\n2017\n210\n30\n\n\n\nDetails about the first 5 are in V.Alexiev et al, Large-scale Reasoning with a Complex Cultural Heritage Ontology (CIDOC CRM), Workshop Practical Experiences with CIDOC CRM and its Extensions (CRMEX), TPDL 2013, slide 17"
  },
  {
    "objectID": "markdown/sample/presentation.html#use-triple-backticks",
    "href": "markdown/sample/presentation.html#use-triple-backticks",
    "title": "Great presentations",
    "section": "4.1 Use triple backticks",
    "text": "4.1 Use triple backticks\nUse markdown style: ```…``` or ```language…```.\nSPARQL/TTL/PIE code will be in Ontotext-specific highlighting style:\nselect *\nwhere {\n    ?s ff-map:mentionsEntity ?entity.\n    ?entity a dbo:Place\n\n    service &lt;http://factforge.net/repositories/ff-news&gt;\n    { ?entity rdfs:label ?label }\n}\nGeneral purpose programing code blocks are also highlighted:\n# Store input numbers\nnum1 = input('Enter first number: ')\nnum2 = input('Enter second number: ')\n\n# Add two numbers\nsum = float(num1) + float(num2)\n\n# Display the sum\nprint('The sum of {0} and {1} is {2}'.format(num1, num2, sum))"
  },
  {
    "objectID": "markdown/sample/presentation.html#code-in-turtlettl",
    "href": "markdown/sample/presentation.html#code-in-turtlettl",
    "title": "Great presentations",
    "section": "4.2 Code in Turtle/TTL",
    "text": "4.2 Code in Turtle/TTL\ngr:Grant                    puml:stereotype \"(G,lightyellow)\" .\ngr:Researcher               puml:stereotype \"(R,lightgreen)\" .\ngr:Funder                   puml:stereotype \"(F,lightgreen)\" .\n&lt;funder/(ADMINISTERING_IC)&gt; puml:stereotype \"(A,lightgreen)\" .\ngr:Grantee                  puml:stereotype \"(G,lightgreen)\" .\ngr:GranteeDepartment        puml:stereotype \"(D,lightgreen)\" .\ngr:Funding                  puml:stereotype \"($,yellow)\" .\ngr:Address                  puml:stereotype \"(A,lightgreen)\" .\ngr:Project                  puml:stereotype \"(P,violet)\" .\ngr:ProjectYear              puml:stereotype \"(Y,violet)\" .\ngr:SubProject               puml:stereotype \"(S,violet)\" .\nskos:Concept                puml:stereotype \"(C,lightblue)\" .\nskos:ConceptScheme          puml:stereotype \"(S,lightblue)\" .\ngr:project                  puml:arrow puml:up.\ngr:projectYear              puml:arrow puml:up.\ngr:subProject               puml:arrow puml:up.\ngr:activityType             puml:arrow puml:down-4.\ngr:applicationType          puml:arrow puml:down-4.\ngr:fundingMechanism         puml:arrow puml:down-4.\ngr:spendingCategory         puml:arrow puml:down-4.\ngr:studySection             puml:arrow puml:down-4.\nowl:sameAs                  puml:arrow puml:left-dashed-none.\n&lt;project/(CORE_PROJECT_NUM)/subProject/(SUBPROJECT_ID)&gt; puml:left &lt;project/(CORE_PROJECT_NUM)/projectYear/(FULL_PROJECT_NUM)&gt;.\ngr:outcomeClinicalTrial   a puml:InlineProperty.\ngr:outcomePatent          a puml:InlineProperty.\ngr:outcomePublication     a puml:InlineProperty.\nrdfs:seeAlso              a puml:InlineProperty.\n\nand then - some text/list item\n\n\n\nCode blocks can be 25 lines of 110 chars"
  },
  {
    "objectID": "markdown/sample/presentation.html#code-in-sparql",
    "href": "markdown/sample/presentation.html#code-in-sparql",
    "title": "Great presentations",
    "section": "4.3 Code in SPARQL",
    "text": "4.3 Code in SPARQL\nprefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nprefix tloimarine: &lt;http://www.ics.forth.gr/isl/ontology/iMarineTLO/&gt;\nprefix tloCore: &lt;http://www.ics.forth.gr/isl/ontology/MarineTLO/&gt;\nSELECT ?waterarea ?area_id ?subarea ?subarea_id ?division ?division_id ?subdivision ?subdivision_id ?subarea_id\nWHERE {\n ?waterarea rdf:type tloCore:BC15_Water_Area .\n ?waterarea tloCore:LC1_is_identified_by ?x.\n ?x tloimarine:assignedCode ?area_id .\n  OPTIONAL {\n    ?waterarea tloCore:LC27_has_section ?subarea .\n    ?subarea tloCore:LC1_is_identified_by ?y.\n    ?y tloimarine:assignedCode ?subarea_id .\n  }\n  OPTIONAL {\n    ?subarea tloCore:LC27_has_section ?division .\n    ?division tloCore:LC1_is_identified_by ?z.\n    ?z tloimarine:assignedCode ?division_id .\n  }\n  OPTIONAL {\n    ?division tloCore:LC27_has_section ?subdivision .\n    ?subdivision tloCore:LC1_is_identified_by ?w.\n    ?w tloimarine:assignedCode ?subdivision_id .\n  }\nFILTER (bound(?subarea_id) || bound(?division_id))\nFILTER (bound(?subdivision_id)) \n}\n\nthis code block has 26 lines, so a scrollbar appears at the right side"
  },
  {
    "objectID": "markdown/sample/presentation.html#code-blocks-can-be-with-triple-apostrophes-as-in-lucene-graphdb-connector-example-but",
    "href": "markdown/sample/presentation.html#code-blocks-can-be-with-triple-apostrophes-as-in-lucene-graphdb-connector-example-but",
    "title": "Great presentations",
    "section": "4.4 Code blocks can be with triple apostrophes, as in Lucene GraphDB connector example, but",
    "text": "4.4 Code blocks can be with triple apostrophes, as in Lucene GraphDB connector example, but\nDon’t use ``` sparql…```, instead, mark code block with ```…```. Ontotext code highlighter “moves” opening curly bracket to the very bottom.\nPREFIX luc: &lt;http://www.ontotext.com/connectors/lucene#&gt;\nPREFIX luc-index: &lt;http://www.ontotext.com/connectors/lucene/instance#&gt;\n\nINSERT DATA {\n    luc-index:my_index luc:createConnector '''\n    { &lt;---this bracket \n  \"types\": [\n    \"http://www.ontotext.com/example/wine#Wine\"\n  ],\n  \"fields\": [\n    {\n      \"fieldName\": \"grape\",\n      \"propertyChain\": [\n        \"http://www.ontotext.com/example/wine#madeFromGrape\",\n        \"http://www.w3.org/2000/01/rdf-schema#label\"\n      ]\n    },\n    {\n      \"fieldName\": \"sugar\",\n      \"propertyChain\": [\n        \"http://www.ontotext.com/example/wine#hasSugar\"\n      ],\n      \"analyzed\": false,\n      \"multivalued\": false\n    },\n    {\n      \"fieldName\": \"year\",\n      \"propertyChain\": [\n        \"http://www.ontotext.com/example/wine#hasYear\"\n      ],\n      \"analyzed\": false\n    }\n  ]\n}''' .\n}"
  },
  {
    "objectID": "markdown/sample/presentation.html#table-styles",
    "href": "markdown/sample/presentation.html#table-styles",
    "title": "Great presentations",
    "section": "5.1 Table styles",
    "text": "5.1 Table styles\nTables can be markdown-style and quarto-style.\n\nMarkdownQuarto-style\n\n\n| Default | Left | Right | Center |\n|---------|:-----|------:|:------:|\n| 12      | 12   |    12 |   12   |\n| 123     | 123  |   123 |  123   |\n| 1       | 1    |     1 |   1    |\n\nresults in\n\n\n\nDefault\nLeft\nRight\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\nSuch code\n::::{.columns}\n::: {.column width=\"30%\"}\n&lt;div class=\"right-centered-text\"&gt;![](../../resources/quarto.png)&lt;/div&gt;\n:::\n::: {.column width=\"70%\"}\nMore text goes here...\n:::\n::::\n\nresults in\n\n\n\n\n\n\nMore text goes here…"
  },
  {
    "objectID": "markdown/sample/presentation.html#quarto-columns",
    "href": "markdown/sample/presentation.html#quarto-columns",
    "title": "Great presentations",
    "section": "5.2 Quarto columns",
    "text": "5.2 Quarto columns\n\n\n\n\n\n\n\nBy default, text in Quarto is left-oriented, but with custom CSS it is possible to change orientation of text\n\n::::{.columns}\n::: {.column width=\"50%\"}\n&lt;div class=\"centered-text\"&gt;\n![](./img/big-picture.png){width=60%}&lt;/div&gt;\n:::\n::: {.column width=\"50%\"}\n&lt;div class=\"right-centered-text\"&gt;\nBy default, text in Quarto is left-oriented, but with custom CSS it is possible to change orientation of text\n&lt;/div&gt;\nImportant: Ctrl + Left mouse button click enlarges a picture / returns to a regular view."
  },
  {
    "objectID": "markdown/sample/presentation.html#quarto-columns-with-images-inside",
    "href": "markdown/sample/presentation.html#quarto-columns-with-images-inside",
    "title": "Great presentations",
    "section": "5.3 Quarto columns with images inside",
    "text": "5.3 Quarto columns with images inside\n\n\n\n\n\n\n\nCurrent solution is: adjust the column widths to see the whole picture without any scale. E.g., these image and text are perfectly seen with column widths 30/70, whereas column widths 50/50 will require adding {width=70%} (or other) to ![](./img/big-picture.png)\n\n::::{.columns}\n::: {.column width=\"30%\"}\n&lt;div class=\"centered-text\"&gt;\n![](./img/big-picture.png)&lt;/div&gt;\n:::\n::: {.column width=\"70%\"}\ntext goes here\n:::\n::::"
  },
  {
    "objectID": "markdown/sample/presentation.html#rendering-large-tables",
    "href": "markdown/sample/presentation.html#rendering-large-tables",
    "title": "Great presentations",
    "section": "5.4 Rendering large tables",
    "text": "5.4 Rendering large tables\n\nuse {.scrollable .smaller} in a slide title markdown or\nuse scrollable: true smaller: true in _metadata.yml\n\nthe minus is that the header of the table is scrollable as well, so when we see last rows of the table, we don’t see the table header.\n\n\n\n\n\nTable\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n7\n\n\n8\n\n\n9\n\n\n10\n\n\n11\n\n\n12\n\n\n13\n\n\n14\n\n\n15\n\n\n16\n\n\n17\n\n\n18\n\n\n19\n\n\n20\n\n\n21\n\n\n22\n\n\n23\n\n\n24\n\n\n25\n\n\n26\n\n\n27\n\n\n28"
  },
  {
    "objectID": "markdown/sample/presentation.html#quarto-side-notes",
    "href": "markdown/sample/presentation.html#quarto-side-notes",
    "title": "Great presentations",
    "section": "6.1 Quarto side notes",
    "text": "6.1 Quarto side notes\n\nWhen you have a main text and a side note, e.g. reference to a paper/project/etc., you can use Quarto-specific markdown. Side notes and footnotes do not have any numbering scheme.\n\n::: aside\n[Side note: reference to a paper](http://ebooks.iospress.nl/doi/10.3233/SSW200034)\n:::\n\n\n\nSide note: reference to a paper"
  },
  {
    "objectID": "markdown/sample/presentation.html#quartomarkdown-footnotes",
    "href": "markdown/sample/presentation.html#quartomarkdown-footnotes",
    "title": "Great presentations",
    "section": "6.2 Quarto/markdown footnotes",
    "text": "6.2 Quarto/markdown footnotes\n\nAlso it is possible to have a footnote in a traditional markdown. Here is a footnote reference [^1] 1 and another [^longnote]2\n\n[^1]: Here is the footnote.\n[^longnote]: Here's one with multiple blocks.\n    Subsequent paragraphs are indented to show that they belong to the previous footnote.\n\nThis will result in:\nHere is the footnote.Here’s one with multiple blocks. Subsequent paragraphs are indented to show that they belong to the previous footnote."
  },
  {
    "objectID": "markdown/sample/presentation.html#bare-links",
    "href": "markdown/sample/presentation.html#bare-links",
    "title": "Great presentations",
    "section": "6.3 Bare links",
    "text": "6.3 Bare links\n\nIn Pandoc:\n\nmd_extension: +autolink_bare_uris\n\nIn Quarto:\n\nbare link is clickable: https://www.wikidata.org/wiki/Q1\nlink in the GitHub Markdown style [text](url) is clickable\nlink surrounded with &lt; &gt; is clickable: https://www.wikidata.org/wiki/Q1"
  },
  {
    "objectID": "markdown/sample/presentation.html#very-long-lists-25-rows",
    "href": "markdown/sample/presentation.html#very-long-lists-25-rows",
    "title": "Great presentations",
    "section": "7.1 Very long lists (25 rows)",
    "text": "7.1 Very long lists (25 rows)\nUse {.smaller} in a slide title markdown\n\n## Very long lists (25 rows) {.smaller}\n\nOr in _metadata.yml write\nformat:\n  reveals:\n    scrollable: true\n    smaller: true\n  ...\n\nFar far away,\nbehind the word mountains,\nfar from the countries Vokalia and Consonantia,\nthere live the blind texts\nSeparated they live\nin Bookmarksgrove right at the coast of the Semantics,\na large language ocean.\nA small river named Duden\nflows by their place\nand supplies it with the necessary regelialia.\nIt is a paradisematic country,\nin which roasted parts of sentences\nfly into your mouth.\nEven the all-powerful Pointing\nhas no control about the blind texts\nit is an almost unorthographic life.\nOne day however\na small line of blind text\nby the name of Lorem Ipsum\ndecided to leave for the far World of Grammar.\nThe Big Oxmox\nadvised her not to do so,\nbecause there were thousands of bad Commas,\nwild Question Marks\nand devious Semikoli\nbut the Little Blind Text didn’t listen."
  },
  {
    "objectID": "markdown/sample/presentation.html#big-picture",
    "href": "markdown/sample/presentation.html#big-picture",
    "title": "Great presentations",
    "section": "7.2 Big picture",
    "text": "7.2 Big picture\n\nThis image is set without ![](img/timeline.png){height=650px}."
  },
  {
    "objectID": "markdown/sample/presentation.html#sec-acknowledgements",
    "href": "markdown/sample/presentation.html#sec-acknowledgements",
    "title": "Great presentations",
    "section": "7.3 Acknowledgements",
    "text": "7.3 Acknowledgements\nTo mention relevant parties in this section, use markdown table and adjust widths of images.\n\nAlternative 1Alternative 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeveloped by\n\nOntotext AD\n\n\nFunded by\n\nHorizon Europe Project ACCORD(101056973)\n\n\nPowered by\n\nOntotext GraphDB\n\n\n\n\nOntotext Platform Semantic Objects\n\n\nData from\n\nbuildingSMART Data Dictionary\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Presentations with beautiful slide decks made by RevealJs"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#workshop-overview",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#workshop-overview",
    "title": "How to Design a Successful SemTech PoC",
    "section": "0.1 Workshop Overview",
    "text": "0.1 Workshop Overview\n\n\n\n\n\n\n\n\nStart- End\nTopic\nDuration\n\n\n\n\n13:00 - 13:15\nIntroduction\n15 min\n\n\n13:15 - 14:00\nSession 1 - Model creation\n45 min\n\n\n14:00 - 14:10\nBreak\n10 min\n\n\n14:10 - 15:00\nSession 2 - ETL process\n50 min\n\n\n15:00 - 15:30\nBreak\n30 min\n\n\n15:30 - 16:30\nSession 3 - Data integration & visualization\n60 min\n\n\n16:30 - 16:40\nBreak\n10 min\n\n\n16:40 - 17:30\nSession 4- Demonstrators (Alex)- Q&A\n50 min"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#url-of-this-presentation",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#url-of-this-presentation",
    "title": "How to Design a Successful SemTech PoC",
    "section": "0.2 URL of this presentation",
    "text": "0.2 URL of this presentation\n0.2.0.1 https://presentations.ontotext.com/semtech-poc.html"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#steps-in-typical-use-case",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#steps-in-typical-use-case",
    "title": "How to Design a Successful SemTech PoC",
    "section": "1.1 Steps in Typical Use Case",
    "text": "1.1 Steps in Typical Use Case\nWhat is a typical use case for a PoC?\n\n\nStart with a question we want answered\nHave some messy data that partially answers the question\n\n\n\n\nPiece of the picture is missing but we can find it in LOD\n\n\n\n\nCreate abstract model presenting the ideal data\n\n\n\n\nTransform messy sources from tabular to graphical form (ETL)\n\n\n\n\nMerge sources into a single dataset\n\n\n\n\nFurther transformation to match data to our ideal data model\n\n\n\n\nUse finalized dataset to get answers"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#our-use-case-1",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#our-use-case-1",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.1 Our Use Case",
    "text": "2.1 Our Use Case\n2.1.1 Nepotism in Hollywood\n. . .\nnepotism /ˈnɛpətɪz(ə)m/\nThe practice among those with power or influence of favouring relatives or friends, especially by giving them jobs.\n. . .\nMid 17th century: from French népotisme, from Italian nepotismo, from nipote ‘nephew’ (with reference to privileges bestowed on the ‘nephews’ of popes, who were in many cases their illegitimate sons)."
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#simplified-imdb-dataset",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#simplified-imdb-dataset",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.2 Simplified IMDB dataset",
    "text": "2.2 Simplified IMDB dataset\n\nOur dataset is a simplified version of the public IMDB dataset\n\ninformation on actors, directors and movies\nno information on family relations of actors"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#sources-for-semantic-integration-lod-cloud",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#sources-for-semantic-integration-lod-cloud",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.3 Sources for Semantic Integration: LOD Cloud",
    "text": "2.3 Sources for Semantic Integration: LOD Cloud\n\nhttps://lod-cloud.net"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#sources-for-semantic-integration-datahub",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#sources-for-semantic-integration-datahub",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.4 Sources for Semantic Integration: Datahub",
    "text": "2.4 Sources for Semantic Integration: Datahub\n\nhttps://datahub.io"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#sources-for-semantic-integration-google",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#sources-for-semantic-integration-google",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.5 Sources for Semantic Integration: Google",
    "text": "2.5 Sources for Semantic Integration: Google\nhttps://toolbox.google.com/datasetsearch\n\nNewest development\n\nNot linked data but can easily be converted\nVery rich\nGrowing very quickly\n\nhttps://console.cloud.google.com/marketplace\n\nLarge and dynamic datasets\nNeed to learn BigQuery and use (and pay for) Google Cloud"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#sources-for-semantic-integration-dbpedia",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#sources-for-semantic-integration-dbpedia",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.6 Sources for semantic Integration: DBPedia",
    "text": "2.6 Sources for semantic Integration: DBPedia\n\nhttp://dbpedia.org/page/Harrison_Ford"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "3.1 Analyse and document peculiarities of source data",
    "text": "3.1 Analyse and document peculiarities of source data\n\n\nnumber of records\n\n\n\n\ncoverage of features (i.e. how many missing features)\n\n\n\n\nrange of numeric features\n\n\n\n\nrange of date features\n\n\n\n\nrepetitive values in text features"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "title": "How to Design a Successful SemTech PoC",
    "section": "4.1 Select existing auxiliary resources relevant to use case",
    "text": "4.1 Select existing auxiliary resources relevant to use case\n\n\nFOAF (Friend of a Friend ontology)\n\n\n\n\nRDFS & OWL - Semantics for Classes, Properties and sameAs equivalence\n\n\n\n\nMovie Ontology, schema.org, (not needed for this POC)"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#etl-basics",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#etl-basics",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.1 ETL Basics",
    "text": "5.1 ETL Basics\n\nExtract\nTransform\nLoad"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#normalise-values",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#normalise-values",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.2 Normalise values",
    "text": "5.2 Normalise values\nOntoRefine text facets allow quick bulk-editing of values\n\nUnited States is normalised to USA in 122 cells"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#create-new-columns",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#create-new-columns",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.3 Create new columns",
    "text": "5.3 Create new columns\nSplit columns according to a separator character"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#urlify",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#urlify",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.4 Urlify",
    "text": "5.4 Urlify\nEdit the text in the cells\n\nRemove whitespace so that the string can be used in a url/iri"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#reconcile",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#reconcile",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.5 Reconcile",
    "text": "5.5 Reconcile\nUse a reconciliation service to match strings to real world objects.\nBulgaria &gt; https://www.wikidata.org/wiki/Q219"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#tabular-to-linked-data",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#tabular-to-linked-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.6 Tabular to Linked Data",
    "text": "5.6 Tabular to Linked Data\nMoving from tabular data to linked data"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#tabular-to-linked-data-1",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#tabular-to-linked-data-1",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.7 Tabular to Linked Data",
    "text": "5.7 Tabular to Linked Data\nHere is what our cleaned up table looks like…"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#tabular-to-linked-data-2",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#tabular-to-linked-data-2",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.8 Tabular to Linked Data",
    "text": "5.8 Tabular to Linked Data\n… but here it is transformed into RDF."
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#tabular-to-linked-data-3",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#tabular-to-linked-data-3",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.9 Tabular to Linked Data",
    "text": "5.9 Tabular to Linked Data"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#initial-data-model",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#initial-data-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.1 Initial data model",
    "text": "6.1 Initial data model\nOutput from our ETL procedure\n\n\nDoes this model contain all the data we need?"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#expanding-the-initial-model",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#expanding-the-initial-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.2 Expanding the initial model",
    "text": "6.2 Expanding the initial model\nIncorporating data from an additional data source.\n\n\nCan we simplify things?"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#creating-a-new-property",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#creating-a-new-property",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.3 Creating a new property",
    "text": "6.3 Creating a new property\nSingle symmetric relation to use in a straightforward manner.\n\n\nCan we simplify things further?"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#creating-a-second-new-property",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#creating-a-second-new-property",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.4 Creating a second new property",
    "text": "6.4 Creating a second new property\nThree relations transformed into a single one.\n\n\nBut we are still working with two disconnected parts."
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#connecting-the-dataset",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#connecting-the-dataset",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.5 Connecting the dataset",
    "text": "6.5 Connecting the dataset\nNow we have everything we need to ask our question.\n\n\nWhat if we want to ask a more complex question?"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#changing-the-model",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#changing-the-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.6 Changing the model",
    "text": "6.6 Changing the model\nAt later stages we can rework the model which will then require corresponding changes to the procedure."
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#google-charts",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#google-charts",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.1 Google charts",
    "text": "7.1 Google charts\nVisualize data in google charts in GDB"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#visual-graph",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#visual-graph",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.2 Visual graph",
    "text": "7.2 Visual graph\nHighly configurable network visualisation using SPARQL"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#visualize-family-relations",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#visualize-family-relations",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.3 Visualize family Relations",
    "text": "7.3 Visualize family Relations"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#visualize-family-relations-2",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#visualize-family-relations-2",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.4 Visualize family Relations 2",
    "text": "7.4 Visualize family Relations 2"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#is-there-nepotism-in-hollywood",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#is-there-nepotism-in-hollywood",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.5 Is there nepotism in Hollywood?",
    "text": "7.5 Is there nepotism in Hollywood?"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#break",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#break",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.6 Break",
    "text": "7.6 Break\n\nDownload materials:\n\nhttp://presentations.ontotext.com/etl-files.zip\n\nDownload and install GraphDB-free for your OS:\n\nWindows: GraphDB_Free-8.11.0.exe\nMac: GraphDB_Free-8.11.0.dmg\nLinux graphdb-free-8.11.0.deb"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#building-a-semantic-poc---steps",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#building-a-semantic-poc---steps",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.7 Building a Semantic POC - Steps",
    "text": "7.7 Building a Semantic POC - Steps\n\nStart with a question we want answered\nHave some data that partially answers the question\nPiece of the picture is missing but we can find it in LOD\nCreate abstract model presenting the ideal data\nTransform sources from tabular to graphical form (ETL)\nMerge sources into a single dataset\nFurther transformation to match data to our ideal data model"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#short-break",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#short-break",
    "title": "How to Design a Successful SemTech PoC",
    "section": "8.1 Short Break",
    "text": "8.1 Short Break\nLoad post-ETL repository:\nhttps://presentations.ontotext.com/movieDB_ETL.trig\nDownload SPARQL queries for next section:\nhttp://presentations.ontotext.com/queries.zip"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#web-application",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#web-application",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.1 Web application",
    "text": "10.1 Web application"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#factforge",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#factforge",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.2 FactForge",
    "text": "10.2 FactForge"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#family-relations-with-agrelon",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#family-relations-with-agrelon",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.3 Family relations with AgReLon",
    "text": "10.3 Family relations with AgReLon\n\nContext\n\nEHRI EC Project\n5M Records of Holocaust survivors and victims (HSV)\n\nTranscripts of lists of names\n\n\n\nData problem\n\nExplicit family relations for 142K pairs (manually constructed by historians)\nMany more in the data\n\nFamilies referenced by common number\nPeople listed with their address\nRelationships between people present (in all european languages)"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#input-data",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#input-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.4 Input Data",
    "text": "10.4 Input Data\n\nFlat CSV format"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#mapping-to-agrelon",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#mapping-to-agrelon",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.5 Mapping to AgRelOn",
    "text": "10.5 Mapping to AgRelOn"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#results",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#results",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.6 Results",
    "text": "10.6 Results\n\nMuch easier querying (agrelon:hasRelative)\nInference of 10K links between previously unconnected nodes (10%)(only grandparents)\nMore possible (cousins)"
  },
  {
    "objectID": "markdown/20180927-SemTechPoC-training/Slides.html#questions",
    "href": "markdown/20180927-SemTechPoC-training/Slides.html#questions",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.7 Questions",
    "text": "10.7 Questions\n\n\n\n@ Semantic PoC Training"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#steps-in-typical-use-case",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#steps-in-typical-use-case",
    "title": "How to Design a Successful SemTech PoC",
    "section": "1.1 Steps in Typical Use Case",
    "text": "1.1 Steps in Typical Use Case\nWhat is a typical use case for a PoC?\n\n\nStart with a question we want answered\nHave some data that partially answers the question\n\n\n\n\nPiece of the picture is missing but we can find it in LOD\n\n\n\n\nCreate abstract model presenting the ideal data\n\n\n\n\nTransform sources from tabular to graphical form (ETL)\n\n\n\n\nMerge sources into a single dataset\n\n\n\n\nFurther transformation to match data to our ideal data model\n\n\n\n\nUse finalized dataset to get answers"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#our-use-case-1",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#our-use-case-1",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.1 Our Use Case",
    "text": "2.1 Our Use Case\n2.1.1 Nepotism in Hollywood\n. . .\nnepotism /ˈnɛpətɪz(ə)m/\nThe practice among those with power or influence of favouring relatives or friends, especially by giving them jobs.\n. . .\nMid 17th century: from French népotisme, from Italian nepotismo, from nipote ‘nephew’ (with reference to privileges bestowed on the ‘nephews’ of popes, who were in many cases their illegitimate sons)."
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#simplified-imdb-dataset",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#simplified-imdb-dataset",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.2 Simplified IMDB dataset",
    "text": "2.2 Simplified IMDB dataset\nOur dataset is a simplified version of the public IMDB dataset"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-lod-cloud",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-lod-cloud",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.3 Sources for Semantic Integration: LOD Cloud",
    "text": "2.3 Sources for Semantic Integration: LOD Cloud\n\nhttps://lod-cloud.net"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-datahub",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-datahub",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.4 Sources for Semantic Integration: Datahub",
    "text": "2.4 Sources for Semantic Integration: Datahub\n\nhttps://datahub.io"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-google-dataset-search",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-google-dataset-search",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.5 Sources for Semantic Integration: Google Dataset Search",
    "text": "2.5 Sources for Semantic Integration: Google Dataset Search"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-google-cloud-public-datasets",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-google-cloud-public-datasets",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.6 Sources for Semantic Integration: Google Cloud Public Datasets",
    "text": "2.6 Sources for Semantic Integration: Google Cloud Public Datasets"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-dbpedia",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#sources-for-semantic-integration-dbpedia",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.7 Sources for semantic Integration: DBPedia",
    "text": "2.7 Sources for semantic Integration: DBPedia\n\nhttps://wiki.dbpedia.org"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "3.1 Analyse and document peculiarities of source data",
    "text": "3.1 Analyse and document peculiarities of source data\n\n\nnumber of records\n\n\n\n\ncoverage of features (i.e. how many missing features)\n\n\n\n\nrange of numeric features\n\n\n\n\nrange of date features\n\n\n\n\nrepetitive values in text features"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "title": "How to Design a Successful SemTech PoC",
    "section": "4.1 Select existing auxiliary resources relevant to use case",
    "text": "4.1 Select existing auxiliary resources relevant to use case\n\n\nFOAF (Friend of a Friend)\n\n\n\n\nOWL\n\n\n\n\nMovie Ontology (not needed for this POC)\n\n\n\n\nOthers to consider"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#etl-basics",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#etl-basics",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.1 ETL Basics",
    "text": "5.1 ETL Basics\nETL is short for extract, transform, load:\n\nExtract: the process of collecting the data, often from multiple and different types of sources.\nTransform: the process of converting the extracted data into the RDF so that it can be placed into GraphDB\nLoad: the process of writing the data into GraphDB\n\n\nIn short, how do we turn multiple datasets of different formats into a single RDF dataset."
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#normalise-values",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#normalise-values",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.2 Normalise values",
    "text": "5.2 Normalise values\nOntoRefine text facets allow quick bulk-editing of values\n\nUnited States is normalised to USA in 122 cells"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#create-new-columns",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#create-new-columns",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.3 Create new columns",
    "text": "5.3 Create new columns\nSplit columns according to a separator character"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#urlify",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#urlify",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.4 Urlify",
    "text": "5.4 Urlify\nEdit the text in the cells\n\nRemove whitespace so that the string can be used in a url/iri"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#reconcile",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#reconcile",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.5 Reconcile",
    "text": "5.5 Reconcile\nUse a reconciliation service to match strings to real world objects.\nBulgaria &gt; https://www.wikidata.org/wiki/Q219"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#tabular-to-linked-data",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#tabular-to-linked-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.6 Tabular to Linked Data",
    "text": "5.6 Tabular to Linked Data\nMoving from tabular data to linked data"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#tabular-to-linked-data-1",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#tabular-to-linked-data-1",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.7 Tabular to Linked Data",
    "text": "5.7 Tabular to Linked Data\nHere is what our cleaned up table looks like…"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#tabular-to-linked-data-2",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#tabular-to-linked-data-2",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.8 Tabular to Linked Data",
    "text": "5.8 Tabular to Linked Data\n… but here it is transformed into RDF."
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#initial-data-model",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#initial-data-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.1 Initial data model",
    "text": "6.1 Initial data model\nOutput from our ETL procedure\n\n\nDoes this model contain all the data we need?"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#expanding-the-initial-model",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#expanding-the-initial-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.2 Expanding the initial model",
    "text": "6.2 Expanding the initial model\nIncorporating data from an additional data source.\n\n\nCan we simplify things?"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#creating-a-new-property",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#creating-a-new-property",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.3 Creating a new property",
    "text": "6.3 Creating a new property\nSingle symmetric relation to use in a straightforward manner.\n\n\nCan we simplify things further?"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#creating-a-second-new-property",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#creating-a-second-new-property",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.4 Creating a second new property",
    "text": "6.4 Creating a second new property\nThree relations transformed into a single one.\n\n\nBut we are still working with two disconnected parts."
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#connecting-the-dataset",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#connecting-the-dataset",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.5 Connecting the dataset",
    "text": "6.5 Connecting the dataset\nNow we have everything we need to ask our question.\n\n\nWhat if we want to ask a more complex question?"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#changing-the-model",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#changing-the-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.6 Changing the model",
    "text": "6.6 Changing the model\nAt later stages we can rework the model which will then require corresponding changes to the procedure."
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#google-charts",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#google-charts",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.1 Google charts",
    "text": "7.1 Google charts\nVisualize data in google charts in GDB"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#visual-graph",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#visual-graph",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.2 Visual graph",
    "text": "7.2 Visual graph\nHighly configurable network visualisation using SPARQL"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#visualize-family-relations",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#visualize-family-relations",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.3 Visualize family Relations",
    "text": "7.3 Visualize family Relations"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#visualize-family-relations-2",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#visualize-family-relations-2",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.4 Visualize family Relations 2",
    "text": "7.4 Visualize family Relations 2"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#is-there-nepotism-in-holywood",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#is-there-nepotism-in-holywood",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.5 Is there nepotism in Holywood?",
    "text": "7.5 Is there nepotism in Holywood?"
  },
  {
    "objectID": "markdown/20180815-SemTechPoc-webinar/Slides.html#building-a-semantic-poc---conclusion",
    "href": "markdown/20180815-SemTechPoc-webinar/Slides.html#building-a-semantic-poc---conclusion",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.6 Building a Semantic POC - Conclusion",
    "text": "7.6 Building a Semantic POC - Conclusion\n\nStart with a question we want answered\nHave some data that partially answers the question\nPiece of the picture is missing but we can find it in LOD\nCreate abstract model presenting the ideal data\nTransform sources from tabular to graphical form (ETL)\nMerge sources into a single dataset\nFurther transformation to match data to our ideal data model"
  },
  {
    "objectID": "markdown/20230921/presentation2.html#use-triple-backticks",
    "href": "markdown/20230921/presentation2.html#use-triple-backticks",
    "title": "Various features",
    "section": "1.1 Use triple backticks",
    "text": "1.1 Use triple backticks\nUse markdown style: ```…``` or ```language…```.\nSPARQL/TTL/PIE code will be in a specific highlighting style:\nselect *\nwhere {\n    ?s ff-map:mentionsEntity ?entity.\n    ?entity a dbo:Place\n\n    service &lt;http://factforge.net/repositories/ff-news&gt;\n    { ?entity rdfs:label ?label }\n}\nGeneral purpose programing code blocks are also highlighted:\n# Store input numbers\nnum1 = input('Enter first number: ')\nnum2 = input('Enter second number: ')\n\n# Add two numbers\nsum = float(num1) + float(num2)\n\n# Display the sum\nprint('The sum of {0} and {1} is {2}'.format(num1, num2, sum))"
  },
  {
    "objectID": "markdown/20230921/presentation2.html#acknowledgements",
    "href": "markdown/20230921/presentation2.html#acknowledgements",
    "title": "Various features",
    "section": "1.2 Acknowledgements",
    "text": "1.2 Acknowledgements\nTo mention relevant parties in this section, use markdown table and adjust widths of images.\n\n\n\nQuarto hints"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#project",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#project",
    "title": "Bank of America POC",
    "section": "1.1 Project",
    "text": "1.1 Project\n\nClient\n\nBank Of America (BOA) - Huge private US bank\nCyber Threat Intelligence (CTI) Department\n\nProject @ Onto\n\n6 month POC\n$50K"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#context---open-source-intelligence",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#context---open-source-intelligence",
    "title": "Bank of America POC",
    "section": "1.2 Context - Open source intelligence",
    "text": "1.2 Context - Open source intelligence\n“Open Source Intelligence (OSINT) is data collected from publicly available sources to be used in an intelligence context.” Lately not only collection but active sharing of info and data\n\nCommercial data providors - MITRE corp, Symantec, Kaspersky\nDedicated data model (STIX)\nMISP Open Source Threat Intelligence Platform & Open Standards For Threat Information Sharing (EU initiative)"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#task---cyber-threat-report-screening",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#task---cyber-threat-report-screening",
    "title": "Bank of America POC",
    "section": "1.3 Task - Cyber Threat report screening",
    "text": "1.3 Task - Cyber Threat report screening\n\nA constant stream of textual documents describing new cyber threats\nHigh priority on being up to date\nHigh load on SME for document screening"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#scope-recap",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#scope-recap",
    "title": "Bank of America POC",
    "section": "1.4 Scope recap",
    "text": "1.4 Scope recap\n\nIntegrate public data sources in a client ontology and build a Knowledge Graph\nAutomatically extract instance data from raw text and further populate the Knowledge Graph\nMain difficulty: Entities manifest at different levels:\n\nSimple Named Entities - (Software, Groups etc) - trivial to annotate automatically using a gazeteer\nComplex entities such as techniques and tactics are more complicated"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#project-outline",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#project-outline",
    "title": "Bank of America POC",
    "section": "1.5 Project outline",
    "text": "1.5 Project outline\n\nData modelling and Integration\nDesign NLP pipeline for processing threat reports\nAnnotate complex entities in text for a training corpus\nBundle in a UI and show value"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-problem",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-problem",
    "title": "Bank of America POC",
    "section": "2.1 The problem",
    "text": "2.1 The problem\n\nClient’s ontology - his first ontology\nSource data in STIX model (json format)\nIngest data and build a KG"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-solution",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-solution",
    "title": "Bank of America POC",
    "section": "2.2 The solution",
    "text": "2.2 The solution\n\nAnalysed and understood the data\nMapping from STIX to client’s model\nDirectly ingested of STIX data using json.ld\nMapping and conversion using SPARQL queres"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#lessons-learned",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#lessons-learned",
    "title": "Bank of America POC",
    "section": "2.3 Lessons learned",
    "text": "2.3 Lessons learned\n\nA lot of effort around validating and tweaking the client’s ontology\nNew data came in after the modelling, integration phase was done\n3 final redundant repos and some last-minute tweaks and kludges.\nShould have worked to stop the datawork and agree on the sources early on"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-problem-1",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-problem-1",
    "title": "Bank of America POC",
    "section": "3.1 The problem",
    "text": "3.1 The problem\n\nAnnotate documents with the relevant business types\nSimple gazeteer based annotations from the KG\nComplex sentence level entities need to somehow be captured"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-solution-1",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-solution-1",
    "title": "Bank of America POC",
    "section": "3.2 The solution",
    "text": "3.2 The solution\n\nGazeteer from KG - based on the DSP Pipeline with most of the stuff removed\nComplex entities not captured by a gazeteer\n\nMachine learning approach (sentence classification)\nNo training data -&gt; have them annotate a bunch of docs"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#lessons-learned-1",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#lessons-learned-1",
    "title": "Bank of America POC",
    "section": "3.3 Lessons learned",
    "text": "3.3 Lessons learned\n\nToo ambitious for a POC\nPossibility of rule-based / string matching approach from the wiki/KG\nBootstrap the manual annotation task\nProblems with lately ingested data\nNo startegy for disambiguation (Malware called “first”), clean up gazetteer by hand…"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-problem-2",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-problem-2",
    "title": "Bank of America POC",
    "section": "4.1 The problem",
    "text": "4.1 The problem\n\nBuild training data for entities of type “Tactic” and “Technique”\nRougly sentence-sized.\nExamples (from manual annotations):\n\n“If a malicious document is opened” : User Execution\n“keylogging capabilities” : Input Capture\n“Encapsulated PostScript (EPS) object is embedded within the document in order to execute” : Scripting"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-solution-2",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-solution-2",
    "title": "Bank of America POC",
    "section": "4.2 The solution",
    "text": "4.2 The solution\n\nSet up a manual annotation task using Ontotext/Data Stork Curation Tool\n\n2 Annotators SME - 1200 docs target\nCollaboratively produce annotation guidelines\n2 days training sessions\n\nCuration tool demo"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#lessons-learned-2",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#lessons-learned-2",
    "title": "Bank of America POC",
    "section": "4.3 Lessons learned",
    "text": "4.3 Lessons learned\n\nManual annotation is hard and costly\n\n60 docs of 1200 annotated docs\nGross underestimation of the effort required\nLack of real commitment from the client\n\nNo clear strategy for managing anonymous annotations and closing the loop to the knowledge graph\nBeta (alpha?) testing a new tool during a commercial project can be messy and stressful\n\nBugs, missing features\nUnclear workflow"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-problem-3",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-problem-3",
    "title": "Bank of America POC",
    "section": "5.1 The problem",
    "text": "5.1 The problem\n\nVisually showcase the work done in the project\nShow annotated documents\nDemo of the Knowledge Graph"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-solution-3",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#the-solution-3",
    "title": "Bank of America POC",
    "section": "5.2 The solution",
    "text": "5.2 The solution\n\nAdapt Ontotext NOW UI to work with Threat Reports\nUse GDB Visual Graph to showcase the Knowledge Graph"
  },
  {
    "objectID": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#lessons-learned-3",
    "href": "markdown/20181214-BankOfAmerica-LunchAndShare/Slides.html#lessons-learned-3",
    "title": "Bank of America POC",
    "section": "5.3 Lessons learned",
    "text": "5.3 Lessons learned\n\nOntotext NOW was too tightly associated with the publishing domain\n\nLead ultimately to a total refactoring (still ongoing)\nEasily deploy the UI in similar projects in the future.\n\nVery good feedback from GDB workbench visual graph\n\nSome usability issues forwarded to GDB team\nNeed to discuss the possibility to somehow get the visualisations out of Workbench"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#scope-and-meetings",
    "href": "markdown/20180718-BDG-WP3/Slides.html#scope-and-meetings",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.1 Scope and Meetings",
    "text": "1.1 Scope and Meetings\n\nWP3 Data & Semantics Layer is a core WP of the project\n\nIf we have no data, we can have no achievements\n\nBetween 30 Apr and 16 July, ONTO hosted 6 project meetings\nCurrently working on T3.1 Data Modelling over Big Data Infrastructures (ONTO, AGRO, AUA, INRA)\nAfter we figure out a semantic data model, we should start on T3.2 Data Ingestion and Integration\nIn parallel (and very soon!), we should start on T3.3 Big Data Indexing (also CNR)\nParticipants (most active listed first):\n\nONTO: Vladimir\nAGRO: Antonis, Pythagoras\nAUA: Katerini\nINRA: Sabine-Karen, Danai?\nOccasional: CNR, Geocledian, Apigea"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#semantic-data-integration-steps",
    "href": "markdown/20180718-BDG-WP3/Slides.html#semantic-data-integration-steps",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.2 Semantic Data Integration Steps",
    "text": "1.2 Semantic Data Integration Steps\n\ndata analysis\ndefining data requirements (competence questions)\nontology engineering: selection, combination and extension of ontologies\n(we are somewhere here)\nsemantic modeling and creating application profiles and/or RDF shapes (SHACL, ShEx)\nsemantic conversion and tools, depending on source (CSV/TSV tabular, RDBMS, XML)\nsemantic alignment and instance matching\nURL design, semantic publishing, content negotiation\ndata validation and data quality management/measurement\ndata update flows\nmodel documentation, sample queries, deploying queries as services"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#minutes-and-resources",
    "href": "markdown/20180718-BDG-WP3/Slides.html#minutes-and-resources",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.3 Minutes and Resources",
    "text": "1.3 Minutes and Resources\n\ngfolder WP3\ngdoc WP3-meeting-minutes has: minutes, background from DOW, links to resources, detailed material\nWhen some material gets bigger, we split it off to a separate file\nGithub repo: https://github.com/BigDataGrapes-EU/ontology (first WP in the project)\n\ndata: semantic data (for now, some samples)\nttl: relevant ontologies converted to turtle (and added prefixes) for easier reading\nmisc: ontology materials in miscellaneous formats (eg xlsx, obo)\nnotes: various notes on ontologies and data.\n\nMirroring between gfolder and Github, bad idea, must decide Github or Google Drive"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#ontologies-researched",
    "href": "markdown/20180718-BDG-WP3/Slides.html#ontologies-researched",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.4 Ontologies Researched",
    "text": "1.4 Ontologies Researched\n\nAGRO submitted sheet Relevant Ontologies and Vocabularies: 16 relevant ontologies, plus 21 on specific crops to use as examples\nONTO downloaded 17 ontologies, converted to ttl which is easier to read\nONTO researched them to some extent and wrote up various problems (see next)\nONTO also researched several ontology portals, with a total of 200 ontologies, 5M classes (!), 16k props, 476k individuals"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#ontology-list",
    "href": "markdown/20180718-BDG-WP3/Slides.html#ontology-list",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.5 Ontology List",
    "text": "1.5 Ontology List\n\n\n\nAEO (OAE): Agricultural Experiments Ontology\nAFEO: Agri-Food Experiment Ontology\nAGRO: Agronomy Ontology\nAT: Agricultural Technology Ontology\nBCO: Biological Collection Ontology\nBFO: Basic Formal Ontology\nChEBI: Chemical Entities of Biological Interest\nCO: Crop Ontology (series of)\n\nCO_320: Rice\nCO_322: Maize\nCO_356: Vitis (viticulture)\nCO_357: Woody Plant\nCO_UO: Units Ontology\n\n\n\n\nEO (ENVO): Environment Ontology\nIAO: Information Artifact Ontology\nMMO: Measurement Methods Ontology\nNCBITaxon: NCBI Taxonomy\nOBO: Open Biological and Biomedical Ontology (a big set)\nOEPO: Ontology for Experimental Phenotypic Objects\nOFPE: Ontology for Food Processing Experiment\nPATO: Phenotypic Quality Ontology\nPCO: Population and Community Ontology\nPECO: Plant and Environemental Conditions Ontology\nPO: Plant Ontology\nRO: Relations Ontology\nSDGIO: SDG-Interface Ontology\nTO: Trait Ontology\nUO: Unit Ontology"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#ontology-metrics",
    "href": "markdown/20180718-BDG-WP3/Slides.html#ontology-metrics",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.6 Ontology Metrics",
    "text": "1.6 Ontology Metrics\n\n\n\n\nClasses\nProperties\nIndividuals\n\n\n\n\nAEO\n56\n36\n30\n\n\nAFEO\n68\n8\n0\n\n\nAGRO\n1685\n709\n284\n\n\nBCO\n157\n279\n28\n\n\nBFO\n35\n20\n\n\n\nCHEBI\n128900\n45\n\n\n\nCO_356\n814\n10\n\n\n\nENVO\n8510\n241\n21\n\n\nFOODON\n27050\n130\n359\n\n\nIAO\n219\n111\n23\n\n\nNCBITaxon\n1692930\n27\n\n\n\n…\n…\n…\n…\n\n\nTOTAL\n1874943\n3598\n1467"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#ontology-portals",
    "href": "markdown/20180718-BDG-WP3/Slides.html#ontology-portals",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.7 Ontology Portals",
    "text": "1.7 Ontology Portals\nUseful to search for terms, see total size, inspiration for our own tools\n\nOBOfoundry: list of ontologies, with resource links\nCropOntology: collaborative ontology development\n\nCO Annotation: annotate tabular data with terms\n\nPlanteome: PO, TO, EO. Tree browser, graph vis\nEBI OLS: 200 ontologies eg agro, Crop Ontologies, Tree browser, graph vis, useful search eg NDVI\n\nEBI OXO: Ontology Xref Service: serves ontology mappings, will integrate to OLS in 2018\n\nGODAN VEST: AgriSemantics Map of Data Standards: 398 ontologies, 215 Food and agriculture, 76 from AgroPortal, 328 from VEST Registry. Eg AEO\nOntoBee: eg PO, AGRO. Detailed Statis, eg PO\nABER OWL: eg AGRO. Simpler browsing"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#aua-tabular-data",
    "href": "markdown/20180718-BDG-WP3/Slides.html#aua-tabular-data",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.8 AUA Tabular Data",
    "text": "1.8 AUA Tabular Data\nTable Grapes Data\n\nLook at data in WP8/Table Grapes Pilot- AUA/Data\nLook in D8.1 Piloting Plan (specifically BigDataGrapes_Piloting Plan-AUA) for descriptions of equipment and measured indicators\nTabular observation data: soil, plant canopies, spectral vegetation indexes\n3 estates: Fasoulis, Kontogiannis, Palivou (see Photos for some images)\nEquipment: EM38, RapidScan, SpectroSense, Crop Circle\nGeo-referenced: longitude, latitude, altitude; timestamped\nAbout 10 measurements per measurement spot\n\nRepresents realistic measurement data - Currently working out a semantic representation to use as etalon for other data"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#data-handling-needs",
    "href": "markdown/20180718-BDG-WP3/Slides.html#data-handling-needs",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.9 Data Handling Needs",
    "text": "1.9 Data Handling Needs\n\n\n\nTo tie measurements to a specific plot: localization of geo-coordinates within the plot (GeoSPARQL predicate within)\nDiscretization (then Averaging) to correlate measurements from different equipment and different days:\n\nOf Geo-coordinates (eg to a grid of 2x2m), then\nOf Datetime (eg is it ok to correlate two measurements done within a day? How about within a week?)\n\nData cleaning: discard defective or outlier measurements\n\nEg1: RapidScan needs some “warm up” time to establish a GPS connection. Discard:\n\nReadings with “FIXTYPE: Fix not valid” (missing)\nReadings with negative ELEVATION (invalid)\n\nEg2: EM38 is affected by metal pillars, so conductivity readings above 100 should be discarded.\n\nEg on Fasoulis_Kato_EM38_map, only the green readings should be retained.\n\n\nMatches Use case A. Data Anomaly Detection & Classification.\n\nEg Eca sensing: Georeferenced soil electrical conductivity data; Operations: Data filtering for outliers"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#inra-rdf-data",
    "href": "markdown/20180718-BDG-WP3/Slides.html#inra-rdf-data",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.10 INRA RDF Data",
    "text": "1.10 INRA RDF Data\n\nINRA submitted two batches, ONTO provided detailed feedback and error reports\ndata3, data4: simple observations. INRA data is top 4 nodes, rest is from Vitis"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#inra-rdf-data-3-4-feedback",
    "href": "markdown/20180718-BDG-WP3/Slides.html#inra-rdf-data-3-4-feedback",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.11 INRA RDF Data 3, 4 Feedback",
    "text": "1.11 INRA RDF Data 3, 4 Feedback\nFeedback ontology/notes#INRA Samples\n\nWrong URL http://www.cropontology.org/ontology/CO_356/Vitis#1000215, should be http://www.cropontology.org/rdf/CO_356:1000215\n\"2016-09-09T00:00:00.0000000Z\"^^xsd:date pads with fake time 0, uses invalid datatype (should be xsd:dateTimeStamp)\nObservations eg http://vinnotec.supagro.inra.fr/public/Pr/data/observation1 are missing rdf:type\nObservation objects eg http://vinnotec.supagro.inra.fr/public/Pr/2016_SUNAGRI_L1_2_C01_Grappe are not defined in these files"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#inra-rdf-data-5",
    "href": "markdown/20180718-BDG-WP3/Slides.html#inra-rdf-data-5",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.12 INRA RDF Data 5",
    "text": "1.12 INRA RDF Data 5\n\n\ndata/INRA/data5.\n\nPlot geometry using GeoSPARQL (geo:asWKT)\nObservations on harvest, fermentation, maturity, must, total sugars (BRIX refractometry)\nINRA_Variables.ttl defines extra terms (maybe they belong in Vitis?)\n\nFedback README.org and HTML rendered\n\nDetailed feedback provided on 7 files, still need to check 5 files\nAbout 30 TODO reported, must turn all of them into DONE"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#data-handling-and-validation",
    "href": "markdown/20180718-BDG-WP3/Slides.html#data-handling-and-validation",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.13 Data Handling and Validation",
    "text": "1.13 Data Handling and Validation\ndata-validation-handling. Started rules on:\n\nHow to submit files (must decide Github or gdrive)\nHow to use and update prefixes.ttl\nHow to validate syntax using riot (and maybe eyeball)\nOnce we decide on patterns for representing data, we will implement RDF Shapes for validating data requirements\n\nHope this will grow to a comprehensive doc on semantic data handling and validation by BDG project partners"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#competence-questions",
    "href": "markdown/20180718-BDG-WP3/Slides.html#competence-questions",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.14 Competence Questions",
    "text": "1.14 Competence Questions\nCompetence Questions - What data you have - What data needs you have, or what questions the data should be able to answer\nGiven the abundance of available data and the sea of agro-bio ontologies, data needs are crucial to keep the modeling effort focused, and drive these tasks:\n\nSeeking more data for specific questions\nDeciding which ontologies to involve and whether more ontological work is needed\nStructuring the data in an appropriate form (semantic modeling)\nDefining data tasks: conversion, cleanup/filtering, discretization…\nCreating sample queries to help data consumers\n\nWe need real, validated competence questions to drive our work"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#agro-competence-questions",
    "href": "markdown/20180718-BDG-WP3/Slides.html#agro-competence-questions",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.15 AGRO Competence Questions",
    "text": "1.15 AGRO Competence Questions\nSubmitted draft Competence Questions:\n\nCan I retrieve the sub-plots for a given plot?\nWhich varieties are cultivated in a given plot?\nCan I retrieve weather data for a given plot?\nWhich varieties are cultivated in a soil with certain characteristics?\nCan I retrieve the origin locale for a given test sample?\nCan I retrieve images of a plot from which a sample was taken\nCan I retrieve historical yield results for a plot (providing a timestamp)?\nCan I retrieve historical weather data for a plot (providing a timestamp)?\n\nNext steps\n\nONTO started elaborating\nAGRO needs to add more details, down detalis such as\n\nAre geolocation qualifiers (satellite, quality, HDOP) needed?\n\nAll partners must validate questions and ground them in (derive them from) Use Cases"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#data-domains",
    "href": "markdown/20180718-BDG-WP3/Slides.html#data-domains",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "1.16 Data Domains",
    "text": "1.16 Data Domains\nWhat data we need to represent?\n\nObservations: when (timestamp), where (georeference), what (measure, dimension, attribute, and observation)\nEstates and plots, including geospatial data\nMeasurement equipment\nExperiments?\nStatic nomenclature data, eg: varieties, types of measurement…\nPhotos… of what?\nWhat else??"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#ontology-problems",
    "href": "markdown/20180718-BDG-WP3/Slides.html#ontology-problems",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "2.1 Ontology Problems",
    "text": "2.1 Ontology Problems\nGithub ontology/notes, rendered HTML\n\nNumerous prefix problems. Collected master file prefixes.ttl, let’s use it\nOntology namespace and ontology file differ significantly, no semantic resolution\nSome ontologies use wrong namespace (URLs don’t mesh), eg Vitis uses rdfs:subProperty (it’s rdfs:subPropertyOf)\nCO_357/nt is invalid, because someone was too lazy to put in new lines\nVarious terms with unfilled labels, eg CO_356:0000309 “name: No method name found”\nViis Mismatch: is CO_356:1000215 measured in grams (name “SBER_W_g”) or milligrams (relation to CO_356:4000018 “mg”)\nClasses, properties and even some ontology files use numeric codes not English names\n\nMakes it necessary to implement some search/browse interface to use them efectively\n\nEven rdfs:label often uses unreadable abbreviations\n\nEg CO_322:0001093 “EWid_M_mm” means Ear width, measurement, in mm\nEg CO_320:0000824 “PanLng_MatAv_UPOV1to3” means rice panicle length, mature - average, UPOV scale, 1..3\n\nSlash in local names make invalid prefixed names, eg CO_322:0000320/2 is value 3=“21-30% dead leaf area” of CO_322:0000320 “0-10 Senescence scale”\nSpace in URL is bad practice, eg rice:Biotic%20stress:\nMany terms declared both skos:Concept, owl:NamedIndividual, owl:Class and connected by both rdfs:subClassOf and skos:broaderTransitive.\n\nrepresents heavy punning and makes OWL inference impossible"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#over-commitment",
    "href": "markdown/20180718-BDG-WP3/Slides.html#over-commitment",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "2.2 Over-Commitment",
    "text": "2.2 Over-Commitment\nIn many cases terms are defined at the wrong level of abstraction\n\nEg NDVI is defined only in Maize, so it can’t be used for grapes (Vitis)\n\nDo we repeat the same mistake in Vitis, or try to move this to the Crop Ontology?\n\nEg CO_UO defines “grams” relative to some woody plant feature. This is crazy because a gram is a gram, no matter what it’s used to measure. So this unit cannot be used for grapes.\n\n  CO_UO:0000021 rdfs:label \"g\"@en; CO:scale_of CO_357:2000105.\n  CO_357:2000105 rdfs:label \"Ratio shoot root protocol\"@en \n\nIt’s better to use a proper Units ontology like QUDT, which defines units in terms of fundamentals (Mass, Length, Time, etc) and conversion factors between units\nNamespace hijacking: redefining imported (external) terms"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#ontology-problems-conclusion",
    "href": "markdown/20180718-BDG-WP3/Slides.html#ontology-problems-conclusion",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "2.3 Ontology Problems: Conclusion",
    "text": "2.3 Ontology Problems: Conclusion\n\nProperty naming convention (lowerCamelCase) not followed, eg po:Tomato rdfs:subPropertyOf  oboInOwl:SubsetProperty\nImproperly formatted timestamps, eg \"Jul 28, 2013 6:56:15 AM\"^^xsd:dateTime\nWrong URL https://www.w3.org/TR/xmlschema-2/#rf-maxInclusive (in some text), should be http://www.w3.org/2001/XMLSchema#maxInclusive (semantic)\nMixup of properties and URLs into a string, eg\noepo:WindSensor rdfs:isDefinedBy \"skos:exactMatch http://purl.oclc.org/NET/ssnx/meteo/aws#WindSensor\" ;\n\nGeneral conclusions\n\nSeems to me there’s very little quality control in AgroBio ontologies\nMaybe a lot of these 200 ontologies and 5M terms are created just to do research, not used in real data\nEngage with the AgroBio community to fix some of the problems"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#not-enough-traction",
    "href": "markdown/20180718-BDG-WP3/Slides.html#not-enough-traction",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "3.1 Not Enough Traction",
    "text": "3.1 Not Enough Traction\nAs you can see on slide “Semantic Data Integration Steps”, we’re still in the beginning. Reasons:\n\nNo effective leadership by AGRO to collect competence questions and liaise with the AgroBio community\nIrregular meeting attendance: only one meeting was attended by all 4 organizations\nLittle progress between meetings\nFeedback (error reports) provided by ONTO received no reaction\nNo collaboration in Github yet (hopefully soon)"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#immediate-next-steps",
    "href": "markdown/20180718-BDG-WP3/Slides.html#immediate-next-steps",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "3.2 Immediate Next Steps",
    "text": "3.2 Immediate Next Steps\n\nAGRO: take the lead on validated Competence Questions\nONTO & AGRO & INRA: establish Ontology Working Group: fixed responsibilities, regular meetings, progress between meetings\nAGRO & INRA: establish collaboration process with the AgroBio community (see 20180623 Modeling Quality): have direct contacts to the persons behind these ontologies (and/or the relevant curation teams)\nINRA & ONTO: map AUA tabular data to ontologies"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#short-term-plans",
    "href": "markdown/20180718-BDG-WP3/Slides.html#short-term-plans",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "3.3 Short-Term Plans",
    "text": "3.3 Short-Term Plans\nDONE\n\nResearch ontologies sent by partners and other related ontologies (AGRO, INRA)\n\nIN-PROGRESS\n\nGet competence questions (AGRO, all partners)\nGet sample tabular data from partners (AUA, others)\nGet sample RDF data from partners (INRA)\nReport ontology and instance data errors to partners\n\nTODO\n\nReport ontology errors to AgroBio community and engage to fix them\nDiscuss how to represent various Data Domains with partners\nCreate a semantic model with rdfpuml\nCreate text narrative (see euBusinessGraph Semantic Model as an example)\nGet the model approved"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#long-term-plans-1",
    "href": "markdown/20180718-BDG-WP3/Slides.html#long-term-plans-1",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "4.1 Long-Term Plans",
    "text": "4.1 Long-Term Plans\n\nCreate RDF shapes for the approved model (SHACL and/or ShEx), establish validation\nResearch and specify possible tools (conversion, annotation, search)\nSelect or implement/deploy tools\nImplement special data processing (eg cleaning, discretization)\nEstablish data ingestion pipeline\nLoad data to GraphDB\nImplement sample queries"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#possible-tool-gdb-ontorefine",
    "href": "markdown/20180718-BDG-WP3/Slides.html#possible-tool-gdb-ontorefine",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "4.2 Possible Tool: GDB OntoRefine",
    "text": "4.2 Possible Tool: GDB OntoRefine\nOntoRefine: part of GDB Workbench, easy cleaning and conversion of tabular data."
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#possible-tool-co-term-annotation",
    "href": "markdown/20180718-BDG-WP3/Slides.html#possible-tool-co-term-annotation",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "4.3 Possible Tool: CO Term Annotation",
    "text": "4.3 Possible Tool: CO Term Annotation\nEg CO Annotation: annotate tabular data with terms\n\nShows that many terms are not found, and ambiguity of terms between ontologies (over-specification)"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#possible-tool-eli-shacl-validator",
    "href": "markdown/20180718-BDG-WP3/Slides.html#possible-tool-eli-shacl-validator",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "4.4 Possible Tool: ELI SHACL Validator",
    "text": "4.4 Possible Tool: ELI SHACL Validator\nEuropean Legislation Identifier Validator"
  },
  {
    "objectID": "markdown/20180718-BDG-WP3/Slides.html#possible-extensionsintegrations",
    "href": "markdown/20180718-BDG-WP3/Slides.html#possible-extensionsintegrations",
    "title": "BigDataGrapes WP3 Status. Montpellier.",
    "section": "4.5 Possible Extensions/Integrations",
    "text": "4.5 Possible Extensions/Integrations\n\nCreate library of shapes (SHACL or ShEx) for validation, with visualization\nAdd library of data shapes (SPARQL CONSTRUCT) to OntoRefine\nIntegrate shape validation to OntoRefine\n\nEtc etc etc. But we first need specifications!"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#about-ontotext",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#about-ontotext",
    "title": "Ontotext CH/DH Projects",
    "section": "1 About Ontotext",
    "text": "1 About Ontotext\n\nFounded 2000, part of Sirma Group (400 people, BSE:SKK, part of SOFIX), venture funding 2008\n65 people: 7 PhD, 30 MS, 20 BS, 6 university lecturers. Offices in Sofia, Varna, London\nCore part of Sirma Strategy 2022 with focus on cognitive computing\nWorking on: semantic technologies, semantic repositories, semantic text analysis, machine learning\nSemantic Graph Database: Ontotext GraphDB\nSemantic data integration and building of Knowledge Graphs\nSemantic text analysis: entity, concept, relation extraction, document classification\nRecommendations, sentiment analysis\nMachine learning: entity disambiguation, deep learning in graphs, etc"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#research-projects",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#research-projects",
    "title": "Ontotext CH/DH Projects",
    "section": "2 Research Projects",
    "text": "2 Research Projects\n\n\n\n\na HTML presentation framework\n\nanimated slides, LaTex support, speaker notes, etc."
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#research-projects-1",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#research-projects-1",
    "title": "Ontotext CH/DH Projects",
    "section": "3 Research Projects",
    "text": "3 Research Projects\n\n\n  \n\nCurrent Projects: * EHRI2: European Holocaust Research Infrastructure (H2020 RI): CH * Evala: Congnitive and Semantic Links Analysis and Media Evaluation Platform (EuroStars) * euBusinessGraph: Innovative Data Products and Services for Company Data (H2020 BigData Experimentation) * COMPACT: From Research Through Policy on Social Media and Convergence (H2020 CSA) * BigDataGrapes: BigData to Enable Global Disruption of the Grapevine-Powered Industries (H2020 BigData Research) * CIMA: Company Intelligent Matching and Linking (BG OPC ISIS)"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#research-and-innovation-awards",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#research-and-innovation-awards",
    "title": "Ontotext CH/DH Projects",
    "section": "4 Research and Innovation Awards",
    "text": "4 Research and Innovation Awards\nArguably, Ontotext is the most innovative Bulgarian software company.\n\nInnovative Enterprise of the Year 2017\nEU Innovation Radar Prize 2016 nomination\nBAIT Business Innovation Award 2014\nInnovative Enterprise of the Year 2014\nWashington Post “Destination Innovation” Competition 2014 Award\nPythagoras Award 2010 for most successful company in EU FP6 projects\n\nWe have more EU research projects than some universities combined"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#industries-and-clients",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#industries-and-clients",
    "title": "Ontotext CH/DH Projects",
    "section": "5 Industries and Clients",
    "text": "5 Industries and Clients\n80% of our sales are in the UK and US\n\nMedia: BBC, UK Press Association, NL Press Association (NDP)…\nFinancial Info: S&P Global Platts, Euromoney, Financial Times, Nikkei…\nSTEM Publishing: IET, Oxford University Press, Wiley, Elsevier, Springer Nature…\nLife Science: AstraZeneca, Novartis…\nGovernment: UK Parliament, The National Archives, Natural Resources Canada…\nCultural Heritage and Digital Humanities (see next)"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#chdh-projects",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#chdh-projects",
    "title": "Ontotext CH/DH Projects",
    "section": "6 CH/DH Projects",
    "text": "6 CH/DH Projects\n\nResearchSpace: British Museum, Yale Center for British Art. Largest museum collection, CIDOC CRM, semantic search…\n(with Sirma Enterprise) ConservationSpace, Sirma MuseumSpace\nMedieval Cultures and Technological Resources (VCMS) COST action\nEuropeana: Creative, Food and Drink (sem app), OAI PMH, SPARQL, members council, 5 work groups, Data Quality Committee\nBulgariana national aggegator: initiator\nGetty Research Institute: vocabularies LOD and helping on Getty Museum LOD\nCarnegie Hall LOD\nAmerican Art Collaborative consulting: 14 US museums integrating data using CIDOC CRM\nEuropean Holocaust Research Infrastructure: semantic archive integration. 4+4 years, heading towards ERIC\nCanadian Heritage Information Network consulting (national aggregator moving to LOD)\nWikidata: frequent contributions (authority control)\nDBpedia: contributions, association member, data quality and ontology committee\nCLADA BG: key participant in both CLARIN (NLP) and DARIAH (CH/DH)"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#knowledge-graphs",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#knowledge-graphs",
    "title": "Ontotext CH/DH Projects",
    "section": "7 Knowledge Graphs",
    "text": "7 Knowledge Graphs\n\n\n\nKnowledge Graph\nYear\nM obj\nB triples\n\n\n\n\nBritish Museum\n2013\n2\n0.92\n\n\nPolish Digital Library\n2013\n3.1\n0.53\n\n\nEuropeana\n2014\n20.3\n3.8\n\n\nFactForge\n2006-now\n~14\n3.2\n\n\nLinkedLifeData\n2008-now\n~12\n10.2\n\n\nCompany Graph\n2017-now\n6\n3\n\n\nDun & Bradstreet\n2017\n210\n30\n\n\n\nDetails about the first 5 are in V.Alexiev et al, Large-scale Reasoning with a Complex Cultural Heritage Ontology (CIDOC CRM), Workshop Practical Experiences with CIDOC CRM and its Extensions (CRMEX), TPDL 2013, slide 17"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#researchspace",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#researchspace",
    "title": "Ontotext CH/DH Projects",
    "section": "8 ResearchSpace",
    "text": "8 ResearchSpace\n\nSemantic integration based on CIDOC CRM, search (first implementation of Fundamental Relations search), data & image annotation, data basket, etc"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#conservationspace",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#conservationspace",
    "title": "Ontotext CH/DH Projects",
    "section": "9 ConservationSpace",
    "text": "9 ConservationSpace\n\nLine-of-business application for conservation specialists. International consortium (US NGA, DK SMK, UK Courtauld etc). Based on the Sirma Enterprise Platform and Ontotext GraphDB, Ontotext helped with the ontologies."
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#museumspace",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#museumspace",
    "title": "Ontotext CH/DH Projects",
    "section": "10 MuseumSpace",
    "text": "10 MuseumSpace\n\nBased on the Sirma Enterprise Platform and ConservationSpace experience. Collections, exhibitions, curation…"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#virtual-center-for-medieval-studies",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#virtual-center-for-medieval-studies",
    "title": "Ontotext CH/DH Projects",
    "section": "11 Virtual Center for Medieval Studies",
    "text": "11 Virtual Center for Medieval Studies\n\nMedieval Cultures and Technological Resources (VCMS) COST action. FET proposals for medieval lexicography, historic research, Virtual Research Environments"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#europeana-creative",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#europeana-creative",
    "title": "Ontotext CH/DH Projects",
    "section": "12 Europeana Creative",
    "text": "12 Europeana Creative\nOAI PMH, and SPARQL servers for Europeana (part of Europeana Labs)."
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#europeana-food-and-drink",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#europeana-food-and-drink",
    "title": "Ontotext CH/DH Projects",
    "section": "13 Europeana Food and Drink",
    "text": "13 Europeana Food and Drink\n\nsem app: enrichment (EN, FR, manual BG), hierarchical semantic facets, contributed BG recipes"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#europeana",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#europeana",
    "title": "Ontotext CH/DH Projects",
    "section": "14 Europeana",
    "text": "14 Europeana\n\nMembers council, 5 task forces (e.g. below: working on FRBRoo-EDM profile), Data Quality Committee"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#bulgariana",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#bulgariana",
    "title": "Ontotext CH/DH Projects",
    "section": "15 Bulgariana",
    "text": "15 Bulgariana\n\nNational aggegator: initiator"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#getty-research-institute-vocabularies-lod",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#getty-research-institute-vocabularies-lod",
    "title": "Ontotext CH/DH Projects",
    "section": "16 Getty Research Institute: Vocabularies LOD",
    "text": "16 Getty Research Institute: Vocabularies LOD\n\nComplete services: GraphDB, ontology design, mapping, documentation, support… Helping on Getty Museum LOD"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#carnegie-hall-lod",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#carnegie-hall-lod",
    "title": "Ontotext CH/DH Projects",
    "section": "17 Carnegie Hall LOD",
    "text": "17 Carnegie Hall LOD"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#american-art-collaborative",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#american-art-collaborative",
    "title": "Ontotext CH/DH Projects",
    "section": "18 American Art Collaborative",
    "text": "18 American Art Collaborative\nConsulting: 14 US museums integrating data using CIDOC CRM. Mapping Review app"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#european-holocaust-research-infrastructure",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#european-holocaust-research-infrastructure",
    "title": "Ontotext CH/DH Projects",
    "section": "19 European Holocaust Research Infrastructure",
    "text": "19 European Holocaust Research Infrastructure\n\nSemantic archive integration. 4+4 years, heading towards ERIC. EAD conversion"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#ehri-ead-validation",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#ehri-ead-validation",
    "title": "Ontotext CH/DH Projects",
    "section": "20 EHRI EAD Validation",
    "text": "20 EHRI EAD Validation\nEAD validation, HTML preview and integrated error display; publishing/transport and ingest to Portal"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#ehri-semantic-services",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#ehri-semantic-services",
    "title": "Ontotext CH/DH Projects",
    "section": "21 EHRI Semantic Services",
    "text": "21 EHRI Semantic Services\n\nGeonames Coreferencing service (from EAD access points etc), EHRI Thesaurus (VocBench), Person Deduplication (record linking)"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#ehri-person-networks",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#ehri-person-networks",
    "title": "Ontotext CH/DH Projects",
    "section": "22 EHRI Person networks",
    "text": "22 EHRI Person networks"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#ehri-camps-and-ghettos",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#ehri-camps-and-ghettos",
    "title": "Ontotext CH/DH Projects",
    "section": "23 EHRI Camps and Ghettos",
    "text": "23 EHRI Camps and Ghettos\n\nIntegrating Camps and Ghettos info between EHRI and Wikidata"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#canadian-heritage-information-network",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#canadian-heritage-information-network",
    "title": "Ontotext CH/DH Projects",
    "section": "24 Canadian Heritage Information Network",
    "text": "24 Canadian Heritage Information Network\n\nCA national aggregator is transitioning to LOD. 4 Consulting projects: environment scan, strategy, Artefacts Canada data analysis, national authorities"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#wikidata-authority-control",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#wikidata-authority-control",
    "title": "Ontotext CH/DH Projects",
    "section": "25 Wikidata Authority Control",
    "text": "25 Wikidata Authority Control"
  },
  {
    "objectID": "markdown/20180613-CLADA-ONTO-CH/Slides.html#wikidatadbpedia-vs-viafgnd-and-europeana",
    "href": "markdown/20180613-CLADA-ONTO-CH/Slides.html#wikidatadbpedia-vs-viafgnd-and-europeana",
    "title": "Ontotext CH/DH Projects",
    "section": "26 Wikidata/DBpedia vs VIAF/GND; and Europeana",
    "text": "26 Wikidata/DBpedia vs VIAF/GND; and Europeana\nName Data Sources for Semantic Enrichment (Europeana Creative D2.4). Wikidata, a Target for Europeana’s Semantic Strategy (GlamWiki 2015)\n\n\n\n\n\n\n\n\n\n\nCLADA-BG Meeting, Sofia"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#workshop-overview",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#workshop-overview",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "0.1 Workshop Overview",
    "text": "0.1 Workshop Overview\n\nPart I: Conceptual Walkthrough\nPart II: ETL with OntoRefine\nPart III: SPARQL and GraphDB Visualization\nPart IV: Demonstrators"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#designing-a-semtech-poc-live-training",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#designing-a-semtech-poc-live-training",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "0.2 Designing a SemTech PoC Live Training",
    "text": "0.2 Designing a SemTech PoC Live Training"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#steps-in-typical-use-case",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#steps-in-typical-use-case",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "1.1 Steps in Typical Use Case",
    "text": "1.1 Steps in Typical Use Case\nWhat is a typical use case for a PoC?\n\n\nStart with a question we want answered\nHave some messy data that partially answers the question\n\n\n\n\nPiece of the picture is missing but we can find it in LOD\n\n\n\n\nCreate abstract model presenting the ideal data\n\n\n\n\nTransform messy sources from tabular to graphical form (ETL)\n\n\n\n\nMerge sources into a single dataset\n\n\n\n\nFurther transformation to match data to our ideal data model\n\n\n\n\nUse finalized dataset to get answers"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#our-use-case-1",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#our-use-case-1",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "2.1 Our Use Case",
    "text": "2.1 Our Use Case\n2.1.1 Nepotism in Hollywood\n. . .\nnepotism /ˈnɛpətɪz(ə)m/\nThe practice among those with power or influence of favouring relatives or friends, especially by giving them jobs.\n. . .\nMid 17th century: from French népotisme, from Italian nepotismo, from nipote ‘nephew’ (with reference to privileges bestowed on the ‘nephews’ of popes, who were in many cases their illegitimate sons)."
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#simplified-imdb-dataset",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#simplified-imdb-dataset",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "2.2 Simplified IMDB dataset",
    "text": "2.2 Simplified IMDB dataset\nOur dataset is a simplified version of the public IMDB dataset"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#sources-for-semantic-integration-lod-cloud",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#sources-for-semantic-integration-lod-cloud",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "2.3 Sources for Semantic Integration: LOD Cloud",
    "text": "2.3 Sources for Semantic Integration: LOD Cloud\n\nhttps://lod-cloud.net"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#sources-for-semantic-integration-datahub",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#sources-for-semantic-integration-datahub",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "2.4 Sources for Semantic Integration: Datahub",
    "text": "2.4 Sources for Semantic Integration: Datahub\n\nhttps://datahub.io"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#sources-for-semantic-integration-dbpedia",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#sources-for-semantic-integration-dbpedia",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "2.5 Sources for semantic Integration: DBPedia",
    "text": "2.5 Sources for semantic Integration: DBPedia\n\nhttps://wiki.dbpedia.org"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "3.1 Analyse and document peculiarities of source data",
    "text": "3.1 Analyse and document peculiarities of source data\n\n\nnumber of records\n\n\n\n\ncoverage of features (i.e. how many missing features)\n\n\n\n\nrange of numeric features\n\n\n\n\nrange of date features\n\n\n\n\nrepetitive values in text features"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "4.1 Select existing auxiliary resources relevant to use case",
    "text": "4.1 Select existing auxiliary resources relevant to use case\n\n\nFOAF (Friend of a Friend)\n\n\n\n\nOWL\n\n\n\n\nMovie Ontology (not needed for this POC)\n\n\n\n\nOthers to consider"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#etl-basics",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#etl-basics",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "5.1 ETL Basics",
    "text": "5.1 ETL Basics"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#normalise-values",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#normalise-values",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "5.2 Normalise values",
    "text": "5.2 Normalise values\nOntoRefine text facets allow quick bulk-editing of values\n\nUnited States is normalised to USA in 122 cells"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#create-new-columns",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#create-new-columns",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "5.3 Create new columns",
    "text": "5.3 Create new columns\nSplit columns according to a separator character"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#urlify",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#urlify",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "5.4 Urlify",
    "text": "5.4 Urlify\nEdit the text in the cells\n\nRemove whitespace so that the string can be used in a url/iri"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#reconcile",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#reconcile",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "5.5 Reconcile",
    "text": "5.5 Reconcile\nUse a reconciliation service to match strings to real world objects.\nBulgaria &gt; https://www.wikidata.org/wiki/Q219"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#tabular-to-linked-data",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#tabular-to-linked-data",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "5.6 Tabular to Linked Data",
    "text": "5.6 Tabular to Linked Data\nMoving from tabular data to linked data"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#tabular-to-linked-data-1",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#tabular-to-linked-data-1",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "5.7 Tabular to Linked Data",
    "text": "5.7 Tabular to Linked Data\nHere is what our cleaned up table looks like…"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#tabular-to-linked-data-2",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#tabular-to-linked-data-2",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "5.8 Tabular to Linked Data",
    "text": "5.8 Tabular to Linked Data\n… but here it is transformed into RDF."
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#initial-data-model",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#initial-data-model",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "6.1 Initial data model",
    "text": "6.1 Initial data model\nOutput from our ETL procedure\n\n\nDoes this model contain all the data we need?"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#expanding-the-initial-model",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#expanding-the-initial-model",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "6.2 Expanding the initial model",
    "text": "6.2 Expanding the initial model\nIncorporating data from an additional data source.\n\n\nCan we simplify things?"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#creating-a-new-property",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#creating-a-new-property",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "6.3 Creating a new property",
    "text": "6.3 Creating a new property\nSingle symmetric relation to use in a straightforward manner.\n\n\nCan we simplify things further?"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#creating-a-second-new-property",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#creating-a-second-new-property",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "6.4 Creating a second new property",
    "text": "6.4 Creating a second new property\nThree relations transformed into a single one.\n\n\nBut we are still working with two disconnected parts."
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#connecting-the-dataset",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#connecting-the-dataset",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "6.5 Connecting the dataset",
    "text": "6.5 Connecting the dataset\nNow we have everything we need to ask our question.\n\n\nWhat if we want to ask a more complex question?"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#changing-the-model",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#changing-the-model",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "6.6 Changing the model",
    "text": "6.6 Changing the model\nAt later stages we can rework the model which will then require corresponding changes to the procedure."
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#google-charts",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#google-charts",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "7.1 Google charts",
    "text": "7.1 Google charts\nVisualize data in google charts in GDB"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#visual-graph",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#visual-graph",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "7.2 Visual graph",
    "text": "7.2 Visual graph\nHighly configurable network visualisation using SPARQL"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#visualize-family-relations",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#visualize-family-relations",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "7.3 Visualize family Relations",
    "text": "7.3 Visualize family Relations"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#visualize-family-relations-2",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#visualize-family-relations-2",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "7.4 Visualize family Relations 2",
    "text": "7.4 Visualize family Relations 2"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#is-there-nepotism-in-hollywood",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#is-there-nepotism-in-hollywood",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "7.5 Is there nepotism in Hollywood?",
    "text": "7.5 Is there nepotism in Hollywood?"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#what-is-sparql",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#what-is-sparql",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.1 What is SPARQL?",
    "text": "8.1 What is SPARQL?\n\nSQL-like query language for RDF data\nSPARQL 1.0 only allowed accessing the data (query)\nSPARQL 1.1 introduced:\n\nQuery extensions: Aggregates, Subqueries, Negation, …\nData management updates: Insert, Delete, Delete/Insert\nGraph management updates: Create, Load, Clear, Drop, Copy, Move, Add"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#what-is-a-sparql-query",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#what-is-a-sparql-query",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.2 What is a SPARQL Query?",
    "text": "8.2 What is a SPARQL Query?\nMain Idea: Pattern matching\n\nQueries describe sub-graphs of the queried graph\nGraph patterns are RDF graphs specified in Turtle syntax, which contain variables (prefixed by either “?” or “$”)\nSub-graphs that match the graph patterns yield a result"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-types",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-types",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.3 Query Types",
    "text": "8.3 Query Types\nThere are four types of queries in SPARQL\n\nASK – test whether a query patterns has a solution (yes/no)\nSELECT – returns variables & their bindings\nCONSTRUCT – returns an RDF graph specified by a graph template\nDESCRIBE – returns an RDF graph containing (all) triples about one or more resources"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-type-ask",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-type-ask",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.4 Query Type ASK",
    "text": "8.4 Query Type ASK\nTest whether a query patterns has a solution\nASK WHERE {?movie mdb:starring ?actor}"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-type-select",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-type-select",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.5 Query Type SELECT",
    "text": "8.5 Query Type SELECT\nReturns variables & their bindings\nSELECT ?movie ?actor WHERE {?movie mdb:starring ?actor}"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-type-construct",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-type-construct",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.6 Query Type CONSTRUCT",
    "text": "8.6 Query Type CONSTRUCT\nReturns an RDF graph specified by a graph template\nCONSTRUCT {?movie1 mdb:hasCommonActorWith ?movie2}\nWHERE {\n    ?movie1 mdb:starring ?commonActor .\n    ?movie2 mdb:starring ?commonActor .\n}"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-type-describe",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#query-type-describe",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.7 Query Type DESCRIBE",
    "text": "8.7 Query Type DESCRIBE\nReturns an RDF graph containing all triples about one or more resources\nDESCRIBE ?movie WHERE {?movie mdb:releaseDate “2011-05-06\"}"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#components-of-a-sparql-query",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#components-of-a-sparql-query",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.8 Components of a SPARQL Query",
    "text": "8.8 Components of a SPARQL Query\n\nList of namespace definitions\n\nPREFIX\n\nQuery form + variables\n\nSELECT, CONSTRUCT, ASK, DESCRIBE\n\nList of data sources (optional)\n\nFROM, FROM NAMED\n\nQuery patterns and filters\n\nWHERE: subqueries, expressions, BIND, VALUES, FILTER\n\nSolution modifiers\n\nORDER BY, LIMIT, OFFSET"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#components-of-a-sparql-query-examples",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#components-of-a-sparql-query-examples",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.9 Components of a SPARQL Query Examples",
    "text": "8.9 Components of a SPARQL Query Examples\nPREFIX mdb: &lt;http://www.example.org/movieDB/&gt;\nPREFIX owl: &lt;http://www.w3.org/2002/07/owl#&gt;\nPREFIX dbr: &lt;http://www.dbpedia.org/resource/&gt;\nPREFIX foaf: &lt;http://xmlns.com/foaf/&gt;\n\nSELECT ?movie ?actor\nFROM &lt;http://www.example.org/movieDB/&gt;\nWHERE {\n    ?movie mdb:starring ?actor .\n} \nORDER BY ASC(?actor)"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#graph-patterns",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#graph-patterns",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.10 Graph Patterns",
    "text": "8.10 Graph Patterns\n\nBasic graph patterns\n\nA conjunction of triple patterns\n\nOptional graph pattern\n\nSpecifies optional parts of a pattern (similar to an “outer join” in SQL)\n\nUnion graph patterns\n\nSpecifies disjunctions (alternatives)"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#sparql-1.1-query-extensions",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#sparql-1.1-query-extensions",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.11 SPARQL 1.1 Query Extensions",
    "text": "8.11 SPARQL 1.1 Query Extensions\n\nAggregates\nSub-queries\nNegation (NOT, NOT EXISTS)\nExpressions in the SELECT clause\nProperty Paths\nAssignment (BIND)\nEnumeration (VALUES)\nA short form for CONSTRUCT\nAn expanded set of functions and operators"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#break",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#break",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.12 Break",
    "text": "8.12 Break\nDownload materials:\nhttp://presentations.ontotext.com/etl-files.zip\nDownload and install GraphDB-free\nhttps://ontotext.com/free-graphdb-download/"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#building-a-semantic-poc---steps",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#building-a-semantic-poc---steps",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "8.13 Building a Semantic POC - Steps",
    "text": "8.13 Building a Semantic POC - Steps\n\nStart with a question we want answered\nHave some data that partially answers the question\nPiece of the picture is missing but we can find it in LOD\nCreate abstract model presenting the ideal data\nTransform sources from tabular to graphical form (ETL)\nMerge sources into a single dataset\nFurther transformation to match data to our ideal data model"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#short-break",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#short-break",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "9.1 Short Break",
    "text": "9.1 Short Break\nLoad post-ETL repository:\nhttps://presentations.ontotext.com/movieDB_ETL.trig\nDownload SPARQL queries for next section:\nhttp://presentations.ontotext.com/queries.zip"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#web-application",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#web-application",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "11.1 Web application",
    "text": "11.1 Web application"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#factforge",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#factforge",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "11.2 FactForge",
    "text": "11.2 FactForge"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#family-relations-with-agrelon",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#family-relations-with-agrelon",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "11.3 Family relations with AgReLon",
    "text": "11.3 Family relations with AgReLon\n\nContext\n\nEHRI EC Project\n5M Records of Holocaust survivors and victims (HSV)\n\nTranscripts of lists of names\n\n\n\nData problem\n\nExplicit family relations for 142K pairs (manually constructed by historians)\nMany more in the data\n\nFamilies referenced by common number\nPeople listed with their address\nRelationships between people present (in all european languages)"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#input-data",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#input-data",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "11.4 Input Data",
    "text": "11.4 Input Data\n\nFlat CSV format"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#mapping-to-agrelon",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#mapping-to-agrelon",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "11.5 Mapping to AgRelOn",
    "text": "11.5 Mapping to AgRelOn"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#results",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#results",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "11.6 Results",
    "text": "11.6 Results\n\nMuch easier querying (agrelon:hasRelative)\nInference of 10K links between previously unconnected nodes (10%)(only grandparents)\nMore possible (cousins)"
  },
  {
    "objectID": "markdown/20180911-SemTechPoC-semantics/Slides.html#questions",
    "href": "markdown/20180911-SemTechPoC-semantics/Slides.html#questions",
    "title": "How to Design a Successful SemTech PoC. @ SEMANTICS18",
    "section": "11.7 Questions",
    "text": "11.7 Questions"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to Ontotext™ presentations! This site contains the updatable index of public presentations Ontotext employees gave in frame of various research projects, tutorial sessions at conferences, internal trainings. The slides are prepared with the help of Quarto publishing system enriched with RevealJS presentation framework.\n© Ontotext AD, 2023. All rights reserved."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "List of presentations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nAuthor\n\n\nDate\n\n\nReading Time\n\n\n\n\n\n\nBank of America POC\n\n\nNikola Tulechki\n\n\nDec 14, 2018\n\n\n5 min\n\n\n\n\nBigDataGrapes WP3 Status. Montpellier.\n\n\nVladimir Alexiev, PhD, PMP & Milena Yankova, PhD\n\n\nJul 18, 2018\n\n\n13 min\n\n\n\n\nGreat presentations\n\n\n\n\n\nSep 18, 2023\n\n\n1 min\n\n\n\n\nGreat presentations\n\n\nNataliya Keberle, data engineer, SOL team\n\n\nSep 18, 2023\n\n\n10 min\n\n\n\n\nHow to Design a Successful SemTech PoC\n\n\nAndrey Tagarev - Ontotext\n\n\nundefined\n\n\n4 min\n\n\n\n\nHow to Design a Successful SemTech PoC\n\n\nAlex Popov, Andrey Tagarev and Nikola Tulechki - Ontotext\n\n\nSep 26, 2019\n\n\n7 min\n\n\n\n\nHow to Design a Successful SemTech PoC\n\n\nAlex Popov, Andrey Tagarev and Nikola Tulechki - Ontotext\n\n\nJan 29, 2019\n\n\n4 min\n\n\n\n\nHow to Design a Successful SemTech PoC\n\n\nAndrey Tagarev and Nikola Tulechki - Ontotext\n\n\nInvalid Date\n\n\n6 min\n\n\n\n\nHow to Design a Successful SemTech PoC. @ SEMANTICS18\n\n\nAndrey Tagarev and Nikola Tulechki - Ontotext\n\n\nSep 11, 2018\n\n\n6 min\n\n\n\n\nImpact of the Ontotext Training Program\n\n\nIvelina Nikolova, Iva Mechkunova, Nikola Tulechki\n\n\nJun 7, 2018\n\n\n8 min\n\n\n\n\nMerge requests in GitLab\n\n\nIvan Ivanov\n\n\nMay 15, 2018\n\n\n3 min\n\n\n\n\nOntotext CH/DH Projects\n\n\nVladimir Alexiev, PhD, PMP\n\n\nJun 1, 2018\n\n\n4 min\n\n\n\n\nOntotext CH/DH Projects\n\n\nVladimir Alexiev, PhD, PMP\n\n\nJun 13, 2018\n\n\n5 min\n\n\n\n\nOntotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018\n\n\nAndrey Tagarev and Nikola Tulechki - Ontotext\n\n\nSep 20, 2018\n\n\n2 min\n\n\n\n\nSemantic Data Integration and the Linked Data Lifecycle\n\n\nNikola Tulechki, Vladimir Alexiev - Ontotext\n\n\nMar 12, 2019\n\n\n22 min\n\n\n\n\nSemantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext\n\n\nNikola Tulechki\n\n\nOct 31, 2018\n\n\n10 min\n\n\n\n\nVarious features\n\n\n\n\n\nSep 18, 2023\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#preparation-for-hands-on-exercises",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#preparation-for-hands-on-exercises",
    "title": "How to Design a Successful SemTech PoC",
    "section": "0.1 Preparation for Hands-On Exercises",
    "text": "0.1 Preparation for Hands-On Exercises\n\nOpen this presentation:\n\nhttp://presentations.ontotext.com/semtech-poc-cleo.html\n\nDownload materials:\n\nhttp://presentations.ontotext.com/etl-files.zip\n\nDownload and install GraphDB-free for your OS:\n\nWindows: GraphDB_Free-8.10.1.exe\nMac: GraphDB_Free-8.10.1.dmg\nLinux graphdb-free-8.10.1.deb"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#workshop-overview",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#workshop-overview",
    "title": "How to Design a Successful SemTech PoC",
    "section": "0.2 Workshop Overview",
    "text": "0.2 Workshop Overview\n\nPart I: Conceptual Walkthrough\nPart II: ETL with OntoRefine\nPart III: SPARQL and GraphDB Visualization\nPart IV: Demonstrators"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#steps-in-typical-use-case",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#steps-in-typical-use-case",
    "title": "How to Design a Successful SemTech PoC",
    "section": "1.1 Steps in Typical Use Case",
    "text": "1.1 Steps in Typical Use Case\nWhat is a typical use case for a PoC?\n\n\nStart with a question we want answered\nHave some messy data that partially answers the question\n\n\n\n\nPiece of the picture is missing but we can find it in LOD\n\n\n\n\nCreate abstract model presenting the ideal data\n\n\n\n\nTransform messy sources from tabular to graphical form (ETL)\n\n\n\n\nMerge sources into a single dataset\n\n\n\n\nFurther transformation to match data to our ideal data model\n\n\n\n\nUse finalized dataset to get answers"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#our-use-case-1",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#our-use-case-1",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.1 Our Use Case",
    "text": "2.1 Our Use Case\n2.1.1 Nepotism in Hollywood\n. . .\nnepotism /ˈnɛpətɪz(ə)m/\nThe practice among those with power or influence of favouring relatives or friends, especially by giving them jobs.\n. . .\nMid 17th century: from French népotisme, from Italian nepotismo, from nipote ‘nephew’ (with reference to privileges bestowed on the ‘nephews’ of popes, who were in many cases their illegitimate sons)."
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#simplified-imdb-dataset",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#simplified-imdb-dataset",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.2 Simplified IMDB dataset",
    "text": "2.2 Simplified IMDB dataset\nOur dataset is a simplified version of the public IMDB dataset"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sources-for-semantic-integration-lod-cloud",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sources-for-semantic-integration-lod-cloud",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.3 Sources for Semantic Integration: LOD Cloud",
    "text": "2.3 Sources for Semantic Integration: LOD Cloud\n\nhttps://lod-cloud.net"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sources-for-semantic-integration-datahub",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sources-for-semantic-integration-datahub",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.4 Sources for Semantic Integration: Datahub",
    "text": "2.4 Sources for Semantic Integration: Datahub\n\nhttps://datahub.io"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sources-for-semantic-integration-google-dataset-search",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sources-for-semantic-integration-google-dataset-search",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.5 Sources for Semantic Integration: Google Dataset Search",
    "text": "2.5 Sources for Semantic Integration: Google Dataset Search"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sources-for-semantic-integration-google-cloud-public-datasets",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sources-for-semantic-integration-google-cloud-public-datasets",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.6 Sources for Semantic Integration: Google Cloud Public Datasets",
    "text": "2.6 Sources for Semantic Integration: Google Cloud Public Datasets\n ## Sources for semantic Integration: DBPedia\n\nhttps://wiki.dbpedia.org"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "3.1 Analyse and document peculiarities of source data",
    "text": "3.1 Analyse and document peculiarities of source data\n\n\nnumber of records\n\n\n\n\ncoverage of features (i.e. how many missing features)\n\n\n\n\nrange of numeric features\n\n\n\n\nrange of date features\n\n\n\n\nrepetitive values in text features"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "title": "How to Design a Successful SemTech PoC",
    "section": "4.1 Select existing auxiliary resources relevant to use case",
    "text": "4.1 Select existing auxiliary resources relevant to use case\n\n\nFOAF (Friend of a Friend)\n\n\n\n\nOWL\n\n\n\n\nMovie Ontology (not needed for this POC)\n\n\n\n\nOthers to consider"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#etl-basics",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#etl-basics",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.1 ETL Basics",
    "text": "5.1 ETL Basics"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#normalise-values",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#normalise-values",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.2 Normalise values",
    "text": "5.2 Normalise values\nOntoRefine text facets allow quick bulk-editing of values\n\nUnited States is normalised to USA in 122 cells"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#create-new-columns",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#create-new-columns",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.3 Create new columns",
    "text": "5.3 Create new columns\nSplit columns according to a separator character"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#urlify",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#urlify",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.4 Urlify",
    "text": "5.4 Urlify\nEdit the text in the cells\n\nRemove whitespace so that the string can be used in a url/iri"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#reconcile",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#reconcile",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.5 Reconcile",
    "text": "5.5 Reconcile\nUse a reconciliation service to match strings to real world objects.\nBulgaria &gt; https://www.wikidata.org/wiki/Q219"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tabular-to-linked-data",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tabular-to-linked-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.6 Tabular to Linked Data",
    "text": "5.6 Tabular to Linked Data\nMoving from tabular data to linked data"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tabular-to-linked-data-1",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tabular-to-linked-data-1",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.7 Tabular to Linked Data",
    "text": "5.7 Tabular to Linked Data\nHere is what our cleaned up table looks like…"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tabular-to-linked-data-2",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tabular-to-linked-data-2",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.8 Tabular to Linked Data",
    "text": "5.8 Tabular to Linked Data\n… but here it is transformed into RDF."
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tabular-to-linked-data-3",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tabular-to-linked-data-3",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.9 Tabular to Linked Data",
    "text": "5.9 Tabular to Linked Data"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#initial-data-model",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#initial-data-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.1 Initial data model",
    "text": "6.1 Initial data model\nOutput from our ETL procedure\n\n\nDoes this model contain all the data we need?"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#expanding-the-initial-model",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#expanding-the-initial-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.2 Expanding the initial model",
    "text": "6.2 Expanding the initial model\nIncorporating data from an additional data source.\n\n\nCan we simplify things?"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#creating-a-new-property",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#creating-a-new-property",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.3 Creating a new property",
    "text": "6.3 Creating a new property\nSingle symmetric relation to use in a straightforward manner.\n\n\nCan we simplify things further?"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#creating-a-second-new-property",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#creating-a-second-new-property",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.4 Creating a second new property",
    "text": "6.4 Creating a second new property\nThree relations transformed into a single one.\n\n\nBut we are still working with two disconnected parts."
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#connecting-the-dataset",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#connecting-the-dataset",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.5 Connecting the dataset",
    "text": "6.5 Connecting the dataset\nNow we have everything we need to ask our question.\n\n\nWhat if we want to ask a more complex question?"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#changing-the-model",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#changing-the-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.6 Changing the model",
    "text": "6.6 Changing the model\nAt later stages we can rework the model which will then require corresponding changes to the procedure."
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#google-charts",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#google-charts",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.1 Google charts",
    "text": "7.1 Google charts\nVisualize data in google charts in GDB"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#visual-graph",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#visual-graph",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.2 Visual graph",
    "text": "7.2 Visual graph\nHighly configurable network visualisation using SPARQL"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#visualize-family-relations",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#visualize-family-relations",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.3 Visualize family Relations",
    "text": "7.3 Visualize family Relations"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#visualize-family-relations-2",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#visualize-family-relations-2",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.4 Visualize family Relations 2",
    "text": "7.4 Visualize family Relations 2"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#is-there-nepotism-in-hollywood",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#is-there-nepotism-in-hollywood",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.5 Is there nepotism in Hollywood?",
    "text": "7.5 Is there nepotism in Hollywood?"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#break",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#break",
    "title": "How to Design a Successful SemTech PoC",
    "section": "8.1 Break",
    "text": "8.1 Break\nLoad post-ETL repository:\nhttps://presentations.ontotext.com/movieDB_ETL.trig\nDownload SPARQL queries for next section:\nhttp://presentations.ontotext.com/queries.zip"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#what-is-sparql",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#what-is-sparql",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.1 What is SPARQL?",
    "text": "9.1 What is SPARQL?\n\nSQL-like query language for RDF data\nSPARQL 1.0 only allowed accessing the data (query)\nSPARQL 1.1 introduced:\n\nQuery extensions: Aggregates, Subqueries, Negation, …\nData management updates: Insert, Delete, Delete/Insert\nGraph management updates: Create, Load, Clear, Drop, Copy, Move, Add"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#what-is-a-sparql-query",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#what-is-a-sparql-query",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.2 What is a SPARQL Query?",
    "text": "9.2 What is a SPARQL Query?\nMain Idea: Pattern matching\n\nQueries describe sub-graphs of the queried graph\nGraph patterns are RDF graphs specified in Turtle syntax, which contain variables (prefixed by either “?” or “$”)\nSub-graphs that match the graph patterns yield a result"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-types",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-types",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.3 Query Types",
    "text": "9.3 Query Types\nThere are four types of queries in SPARQL\n\nASK – test whether a query patterns has a solution (yes/no)\nSELECT – returns variables & their bindings\nCONSTRUCT – returns an RDF graph specified by a graph template\nDESCRIBE – returns an RDF graph containing (all) triples about one or more resources"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-type-ask",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-type-ask",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.4 Query Type ASK",
    "text": "9.4 Query Type ASK\nTest whether a query patterns has a solution\nASK WHERE {?movie mdb:starring ?actor}"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-type-select",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-type-select",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.5 Query Type SELECT",
    "text": "9.5 Query Type SELECT\nReturns variables & their bindings\nSELECT ?movie ?actor WHERE {?movie mdb:starring ?actor}"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-type-construct",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-type-construct",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.6 Query Type CONSTRUCT",
    "text": "9.6 Query Type CONSTRUCT\nReturns an RDF graph specified by a graph template\nCONSTRUCT {?movie1 mdb:hasCommonActorWith ?movie2}\nWHERE {\n    ?movie1 mdb:starring ?commonActor .\n    ?movie2 mdb:starring ?commonActor .\n}"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-type-describe",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#query-type-describe",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.7 Query Type DESCRIBE",
    "text": "9.7 Query Type DESCRIBE\nReturns an RDF graph containing all triples about one or more resources\nDESCRIBE ?movie WHERE {?movie mdb:releaseDate “2011-05-06\"}"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#components-of-a-sparql-query",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#components-of-a-sparql-query",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.8 Components of a SPARQL Query",
    "text": "9.8 Components of a SPARQL Query\n\nList of namespace definitions\n\nPREFIX\n\nQuery form + variables\n\nSELECT, CONSTRUCT, ASK, DESCRIBE\n\nList of data sources (optional)\n\nFROM, FROM NAMED\n\nQuery patterns and filters\n\nWHERE: subqueries, expressions, BIND, VALUES, FILTER\n\nSolution modifiers\n\nORDER BY, LIMIT, OFFSET"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#components-of-a-sparql-query-examples",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#components-of-a-sparql-query-examples",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.9 Components of a SPARQL Query Examples",
    "text": "9.9 Components of a SPARQL Query Examples\nPREFIX mdb: &lt;http://www.example.org/movieDB/&gt;\nPREFIX owl: &lt;http://www.w3.org/2002/07/owl#&gt;\nPREFIX dbr: &lt;http://www.dbpedia.org/resource/&gt;\nPREFIX foaf: &lt;http://xmlns.com/foaf/&gt;\n\nSELECT ?movie ?actor\nFROM &lt;http://www.example.org/movieDB/&gt;\nWHERE {\n    ?movie mdb:starring ?actor .\n} \nORDER BY ASC(?actor)"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#graph-patterns",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#graph-patterns",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.10 Graph Patterns",
    "text": "9.10 Graph Patterns\n\nBasic graph patterns\n\nA conjunction of triple patterns\n\nOptional graph pattern\n\nSpecifies optional parts of a pattern (similar to an “outer join” in SQL)\n\nUnion graph patterns\n\nSpecifies disjunctions (alternatives)"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sparql-1.1-query-extensions",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#sparql-1.1-query-extensions",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.11 SPARQL 1.1 Query Extensions",
    "text": "9.11 SPARQL 1.1 Query Extensions\n\nAggregates\nSub-queries\nNegation (NOT, NOT EXISTS)\nExpressions in the SELECT clause\nProperty Paths\nAssignment (BIND)\nEnumeration (VALUES)\nA short form for CONSTRUCT\nAn expanded set of functions and operators"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#building-a-semantic-poc---steps",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#building-a-semantic-poc---steps",
    "title": "How to Design a Successful SemTech PoC",
    "section": "9.12 Building a Semantic POC - Steps",
    "text": "9.12 Building a Semantic POC - Steps\n\nStart with a question we want answered\nHave some data that partially answers the question\nPiece of the picture is missing but we can find it in LOD\nCreate abstract model presenting the ideal data\nTransform sources from tabular to graphical form (ETL)\nMerge sources into a single dataset\nFurther transformation to match data to our ideal data model"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tag",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#tag",
    "title": "How to Design a Successful SemTech PoC",
    "section": "11.1 TAG",
    "text": "11.1 TAG\nNamed Entity Recognition and Linking\n\nhttp://tag.ontotext.com/"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#now",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#now",
    "title": "How to Design a Successful SemTech PoC",
    "section": "11.2 NOW",
    "text": "11.2 NOW\nNews on the Web Demonstrator\n\nhttp://now.ontotext.com/"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#factforge",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#factforge",
    "title": "How to Design a Successful SemTech PoC",
    "section": "11.3 FactForge",
    "text": "11.3 FactForge\nLinked Data Hub\n\nhttp://factforge.net"
  },
  {
    "objectID": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#questions",
    "href": "markdown/20190909-SemTechPoC-CLEOPATRA/Slides.html#questions",
    "title": "How to Design a Successful SemTech PoC",
    "section": "11.4 Questions",
    "text": "11.4 Questions"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#workshop-overview",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#workshop-overview",
    "title": "How to Design a Successful SemTech PoC",
    "section": "0.1 Workshop Overview",
    "text": "0.1 Workshop Overview\n\nSession 1 - Model Creation\nSession 2 - ETL Process\nSession 3 - Data Integration & Visualization\nSession 4 - Demonstrators"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#steps-in-typical-use-case",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#steps-in-typical-use-case",
    "title": "How to Design a Successful SemTech PoC",
    "section": "1.1 Steps in Typical Use Case",
    "text": "1.1 Steps in Typical Use Case\nWhat is a typical use case for a PoC?\n\n\nStart with a question we want answered\nHave some messy data that partially answers the question\n\n\n\n\nPiece of the picture is missing but we can find it in LOD\n\n\n\n\nCreate abstract model presenting the ideal data\n\n\n\n\nTransform messy sources from tabular to graphical form (ETL)\n\n\n\n\nMerge sources into a single dataset\n\n\n\n\nFurther transformation to match data to our ideal data model\n\n\n\n\nUse finalized dataset to get answers"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#our-use-case-1",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#our-use-case-1",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.1 Our Use Case",
    "text": "2.1 Our Use Case\n2.1.1 Nepotism in Hollywood\n. . .\nnepotism /ˈnɛpətɪz(ə)m/\nThe practice among those with power or influence of favouring relatives or friends, especially by giving them jobs.\n. . .\nMid 17th century: from French népotisme, from Italian nepotismo, from nipote ‘nephew’ (with reference to privileges bestowed on the ‘nephews’ of popes, who were in many cases their illegitimate sons)."
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#simplified-imdb-dataset",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#simplified-imdb-dataset",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.2 Simplified IMDB dataset",
    "text": "2.2 Simplified IMDB dataset\nOur dataset is a simplified version of the public IMDB dataset"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#sources-for-semantic-integration-lod-cloud",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#sources-for-semantic-integration-lod-cloud",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.3 Sources for Semantic Integration: LOD Cloud",
    "text": "2.3 Sources for Semantic Integration: LOD Cloud\n\nhttps://lod-cloud.net"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#sources-for-semantic-integration-datahub",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#sources-for-semantic-integration-datahub",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.4 Sources for Semantic Integration: Datahub",
    "text": "2.4 Sources for Semantic Integration: Datahub\n\nhttps://datahub.io"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#sources-for-semantic-integration-google-data-search",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#sources-for-semantic-integration-google-data-search",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.5 Sources for Semantic Integration: Google Data Search",
    "text": "2.5 Sources for Semantic Integration: Google Data Search\nhttps://toolbox.google.com/datasetsearch\n\nNewest development\nNot linked data but can easily be converted\nVery rich\nGrowing very quickly"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#sources-for-semantic-integration-dbpedia",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#sources-for-semantic-integration-dbpedia",
    "title": "How to Design a Successful SemTech PoC",
    "section": "2.6 Sources for semantic Integration: DBPedia",
    "text": "2.6 Sources for semantic Integration: DBPedia\n\nhttps://wiki.dbpedia.org"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#analyse-and-document-peculiarities-of-source-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "3.1 Analyse and document peculiarities of source data",
    "text": "3.1 Analyse and document peculiarities of source data\n\n\nnumber of records\n\n\n\n\ncoverage of features (i.e. how many missing features)\n\n\n\n\nrange of numeric features\n\n\n\n\nrange of date features\n\n\n\n\nrepetitive values in text features"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#select-existing-auxiliary-resources-relevant-to-use-case",
    "title": "How to Design a Successful SemTech PoC",
    "section": "4.1 Select existing auxiliary resources relevant to use case",
    "text": "4.1 Select existing auxiliary resources relevant to use case\n\n\nFOAF (Friend of a Friend)\n\n\n\n\nOWL\n\n\n\n\nMovie Ontology (not needed for this POC)\n\n\n\n\nOthers to consider"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#movie-ontology",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#movie-ontology",
    "title": "How to Design a Successful SemTech PoC",
    "section": "4.2 Movie Ontology",
    "text": "4.2 Movie Ontology\nhttp://movieontology.org/wp-content/uploads/2014/03/MO2.png"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#etl-basics",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#etl-basics",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.1 ETL Basics",
    "text": "5.1 ETL Basics"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#normalise-values",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#normalise-values",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.2 Normalise values",
    "text": "5.2 Normalise values\nOntoRefine text facets allow quick bulk-editing of values\n\nUnited States is normalised to USA in 122 cells"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#create-new-columns",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#create-new-columns",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.3 Create new columns",
    "text": "5.3 Create new columns\nSplit columns according to a separator character"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#urlify",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#urlify",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.4 Urlify",
    "text": "5.4 Urlify\nEdit the text in the cells\n\nRemove whitespace so that the string can be used in a url/iri"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#reconcile",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#reconcile",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.5 Reconcile",
    "text": "5.5 Reconcile\nUse a reconciliation service to match strings to real world objects.\nBulgaria &gt; https://www.wikidata.org/wiki/Q219"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#tabular-to-linked-data",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#tabular-to-linked-data",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.6 Tabular to Linked Data",
    "text": "5.6 Tabular to Linked Data\nMoving from tabular data to linked data"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#tabular-to-linked-data-1",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#tabular-to-linked-data-1",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.7 Tabular to Linked Data",
    "text": "5.7 Tabular to Linked Data\nHere is what our cleaned up table looks like…"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#tabular-to-linked-data-2",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#tabular-to-linked-data-2",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.8 Tabular to Linked Data",
    "text": "5.8 Tabular to Linked Data\n… but here it is transformed into RDF."
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#tabular-to-linked-data-3",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#tabular-to-linked-data-3",
    "title": "How to Design a Successful SemTech PoC",
    "section": "5.9 Tabular to Linked Data",
    "text": "5.9 Tabular to Linked Data"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#initial-data-model",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#initial-data-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.1 Initial data model",
    "text": "6.1 Initial data model\nOutput from our ETL procedure\n\n\nDoes this model contain all the data we need?"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#expanding-the-initial-model",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#expanding-the-initial-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.2 Expanding the initial model",
    "text": "6.2 Expanding the initial model\nIncorporating data from an additional data source.\n\n\nCan we simplify things?"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#creating-a-new-property",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#creating-a-new-property",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.3 Creating a new property",
    "text": "6.3 Creating a new property\nSingle symmetric relation to use in a straightforward manner.\n\n\nCan we simplify things further?"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#creating-a-second-new-property",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#creating-a-second-new-property",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.4 Creating a second new property",
    "text": "6.4 Creating a second new property\nThree relations transformed into a single one.\n\n\nBut we are still working with two disconnected parts."
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#connecting-the-dataset",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#connecting-the-dataset",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.5 Connecting the dataset",
    "text": "6.5 Connecting the dataset\nNow we have everything we need to ask our question.\n\n\nWhat if we want to ask a more complex question?"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#changing-the-model",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#changing-the-model",
    "title": "How to Design a Successful SemTech PoC",
    "section": "6.6 Changing the model",
    "text": "6.6 Changing the model\nAt later stages we can rework the model which will then require corresponding changes to the procedure."
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#google-charts",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#google-charts",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.1 Google charts",
    "text": "7.1 Google charts\nVisualize data in google charts in GDB"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#visual-graph",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#visual-graph",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.2 Visual graph",
    "text": "7.2 Visual graph\nHighly configurable network visualisation using SPARQL"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#visualize-family-relations",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#visualize-family-relations",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.3 Visualize family Relations",
    "text": "7.3 Visualize family Relations"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#visualize-family-relations-2",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#visualize-family-relations-2",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.4 Visualize family Relations 2",
    "text": "7.4 Visualize family Relations 2"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#is-there-nepotism-in-hollywood",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#is-there-nepotism-in-hollywood",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.5 Is there nepotism in Hollywood?",
    "text": "7.5 Is there nepotism in Hollywood?"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#break",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#break",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.6 Break",
    "text": "7.6 Break\nDownload materials:\nhttp://presentations.ontotext.com/etl-files.zip\nDownload and install GraphDB-free\nhttps://ontotext.com/free-graphdb-download/"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#building-a-semantic-poc---steps",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#building-a-semantic-poc---steps",
    "title": "How to Design a Successful SemTech PoC",
    "section": "7.7 Building a Semantic POC - Steps",
    "text": "7.7 Building a Semantic POC - Steps\n\nStart with a question we want answered\nHave some data that partially answers the question\nPiece of the picture is missing but we can find it in LOD\nCreate abstract model presenting the ideal data\nTransform sources from tabular to graphical form (ETL)\nMerge sources into a single dataset\nFurther transformation to match data to our ideal data model"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#short-break",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#short-break",
    "title": "How to Design a Successful SemTech PoC",
    "section": "8.1 Short Break",
    "text": "8.1 Short Break\nLoad post-ETL repository:\nhttps://presentations.ontotext.com/movieDB_ETL.trig\nDownload SPARQL queries for next section:\nhttp://presentations.ontotext.com/queries.zip"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#factforge",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#factforge",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.1 FactForge",
    "text": "10.1 FactForge"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#reconciliation",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#reconciliation",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.2 Reconciliation",
    "text": "10.2 Reconciliation"
  },
  {
    "objectID": "markdown/20190130-SemTechPoC-psa/Slides.html#questions",
    "href": "markdown/20190130-SemTechPoC-psa/Slides.html#questions",
    "title": "How to Design a Successful SemTech PoC",
    "section": "10.3 Questions",
    "text": "10.3 Questions\n\n\n\n@ Semantic PoC Training"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#re-occurring-trainings",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#re-occurring-trainings",
    "title": "Impact of the Ontotext Training Program",
    "section": "1.1 Re-occurring Trainings",
    "text": "1.1 Re-occurring Trainings\n\nDesigning Semantic Technologies PoC\n\npre-training - 1 week engagement\nonline training - 5h\n\nGraphDB for DevOps\n\npre-training - 1 week engagement\nonline training - 3 days x 6h\n\nSemantic Data Integration (Tentative)"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#custom-trainings",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#custom-trainings",
    "title": "Impact of the Ontotext Training Program",
    "section": "1.2 Custom Trainings",
    "text": "1.2 Custom Trainings\n\nSemantic Technologies & GATE @JP Morgan&Chase\nLD Sources, Robust Text Analysis and Semantic Search @SEMANTICS’2017\nSemantic Technologies _@ArcelorMittal_ - online\nGold Standard Corpora _@Platts_ - online\nGATE NLP Platform _@IET_ - online"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#collaboration-with-universities",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#collaboration-with-universities",
    "title": "Impact of the Ontotext Training Program",
    "section": "1.3 Collaboration with Universities",
    "text": "1.3 Collaboration with Universities\n\nFMI, University of Sofia (Prof. Maria Nisheva and Prof. Ivan Koychev)\n\nmaterials for courses: “Knowledge modelling and representation” and “Knowledge bases”, taught for MSc in AI\nlecturing in AI course taught for BSc in Computer Science\n\nUniversity of Aberdeen (Ass. Prof. Adam Wyner, currently at Swansea University)\n\nmaterials for the course “Knowledge Representation and Reasoning”, taught for MSc in Computing Science\n\nESSLLI 2018\n\nhands-on with GraphDB and technical support for the course “Introduction to Linked Open Data in Linguistics”, Thierry Declerck and John P. McCrae"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#trainings-calendar",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#trainings-calendar",
    "title": "Impact of the Ontotext Training Program",
    "section": "1.4 Trainings’ Calendar",
    "text": "1.4 Trainings’ Calendar"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#agenda",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#agenda",
    "title": "Impact of the Ontotext Training Program",
    "section": "2.1 Agenda",
    "text": "2.1 Agenda\n\n3h video tutorials on Semantic Technologies (pre-training)\nHands-on with SPARQL (pre-training)\nDesigning a PoC with GraphDB (live session)\n\nDiscussing the principles of design\nETL process\nBasic data modelling\nQuerying the data - demonstrating the power of LOD through federation\nDemonstrating helpful GraphDB features - autocomplete, namespaces, visual graph, exploration of resources and class hierarchy\nDemonstrating OT demos - Rank, NOW\n\nIndividual sessions - 1h devoted time to a given participant"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#poc-training-progress-and-outcomes",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#poc-training-progress-and-outcomes",
    "title": "Impact of the Ontotext Training Program",
    "section": "2.2 PoC Training Progress and Outcomes",
    "text": "2.2 PoC Training Progress and Outcomes\n\n7 editions of the training\nImprovement of the materials over time according to the user feedback\n\nfrom a demonstration with OntoRefine and a couple of SPARQL queries in Dec 2016\nto a smooth workflow including a real design of a PoC passing through all the steps of the design in Mar 2018\n\nRaising number of involved trainers - people who can jump in and lecture part of it\n\n1 tutor in Dec 2016\n5 tutors in Mar 2018\n\nTraining of OT newcomers - 3\nTraining of potential clients or partners\nReuse of materials for other training and webinars"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#agenda-1",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#agenda-1",
    "title": "Impact of the Ontotext Training Program",
    "section": "3.1 Agenda",
    "text": "3.1 Agenda\n\n3h video tutorials on Semantic Technologies (pre-training)\nHands-on with SPARQL (pre-training)\n\nProduct editions and features\nGraphDB Quick Start\nProduct APIs\nSPARQL\nReasoning\nConnectors\nAdministration & Monitoring"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#graphdb-for-devops-training-progress-and-outcomes",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#graphdb-for-devops-training-progress-and-outcomes",
    "title": "Impact of the Ontotext Training Program",
    "section": "3.2 GraphDB for DevOps Training Progress and Outcomes",
    "text": "3.2 GraphDB for DevOps Training Progress and Outcomes\n\n1 internal edition of the training\n1 public edition of the training\nImprovement of the materials over time according to the user feedback - the internal training contributed much about it\nRaising number of involved trainers - people who can jump in and lecture part of it\n\n5 in January 2018\n7 in May 2018\n\nTraining of OT developers - 12\nTraining of potential clients or partners\nReuse of materials for other training and webinars"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#participants",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#participants",
    "title": "Impact of the Ontotext Training Program",
    "section": "4.1 Participants",
    "text": "4.1 Participants\n\nDesigning SemTech PoC: a total of 153 participants spread over 7 editions of the training\n\n\n\nGraphDB for DevOps: two participants so far"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#companies-by-country",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#companies-by-country",
    "title": "Impact of the Ontotext Training Program",
    "section": "4.2 Companies by Country",
    "text": "4.2 Companies by Country\n\nDesigning SemTech PoC\n\n\n\nGraphDB for DevOps: Canada, Holland"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#companies-by-country---designing-semtech-poc",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#companies-by-country---designing-semtech-poc",
    "title": "Impact of the Ontotext Training Program",
    "section": "4.3 Companies by Country - Designing SemTech PoC",
    "text": "4.3 Companies by Country - Designing SemTech PoC\n\n\n\n\n\n\n\n\n\n\n\ncountry\ncount\ncountry\ncount\ncountry\ncount\n\n\n\n\nUSA\n36\nGreece\n2\nLithuania\n1\n\n\nUnited Kingdom\n18\nLuxembourg\n2\nNew Zealand\n1\n\n\nGermany\n12\nNetherlands\n2\nPortugal\n1\n\n\nFrance\n8\nSaudi Arabia\n2\nRomania\n1\n\n\nIndia\n8\nThe Netherlands\n2\nSingapore\n1\n\n\nCanada\n7\nDenmark\n1\nSweden\n1\n\n\nSpain\n6\nEcuador\n1\nUkraine\n1\n\n\nBulgaria\n5\nEgypt\n1\n\n\n\n\nItaly\n5\nFinland\n1\n\n\n\n\nSwitzerland\n4\nHong Kong\n1\n\n\n\n\nAustralia\n2\nIreland\n1\n\n\n\n\nBelgium\n2\nIsrael\n1"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#companies-by-country---graphdb-for-devops",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#companies-by-country---graphdb-for-devops",
    "title": "Impact of the Ontotext Training Program",
    "section": "4.4 Companies by Country - GraphDB for DevOps",
    "text": "4.4 Companies by Country - GraphDB for DevOps\n\n\n\ncompany\ncountry\nindustry\n\n\n\n\nKadaster\nThe Netherlands\nGovernment\n\n\nSemantic World\nCanada\nTechnology"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#participants-by-job-titles",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#participants-by-job-titles",
    "title": "Impact of the Ontotext Training Program",
    "section": "4.5 Participants by Job Titles",
    "text": "4.5 Participants by Job Titles"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#participants-by-use-case-i",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#participants-by-use-case-i",
    "title": "Impact of the Ontotext Training Program",
    "section": "4.6 Participants by Use Case I",
    "text": "4.6 Participants by Use Case I\n\nWeb-based catalogue for technologies\nKnowledge-based web service to provide information on heating and cooling technologies\nThe project focuses on the biological annotation of cancer evolutionary dynamics, and will harness semantic annotation for\n\nminimizing concept ambiguity,\nlinking our data to an external and evolving KB, like Wikidata, and\nmaking smarter and federated queries on a structured KB.\n\nUsing healthcare records stored in an RDF triple store\nAnalysing text documents, building ontologies to support natural language QA\nAutomatically crawling and structuring data on performing arts websites in Canada to enable complex queries and export JSON-LD event entities for search engines."
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#participants-by-use-case-ii",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#participants-by-use-case-ii",
    "title": "Impact of the Ontotext Training Program",
    "section": "4.7 Participants by Use Case II",
    "text": "4.7 Participants by Use Case II\n\nUsing of ontologies and inference for business processes/workflows\nA project similar to now.ontotext.com\nLOD projects\nHaving a big set of linked data consisting of airborne and Open Street data of United Kingdom, I want to find the schools and the hospitals which are in a region with polluted air. Children and patients are the most vulnerable group of people and they should take care of the environment where they live in.\nPredictive maintenance of aircraft fleet based on a range of data sources"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#revenue",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#revenue",
    "title": "Impact of the Ontotext Training Program",
    "section": "4.8 Revenue",
    "text": "4.8 Revenue\n\nPositive financial result for 2017 for online trainings\nSince materials from the online trainings are reused for client custom trainings, we do have good profit from the client trainings\nThe financial result as of April 2018 is still negative however the incomes from May are not calculated yet and the balance should be good at the end"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#channels-for-attracting-users-i",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#channels-for-attracting-users-i",
    "title": "Impact of the Ontotext Training Program",
    "section": "5.1 Channels for Attracting Users I",
    "text": "5.1 Channels for Attracting Users I\n\nEmail - the main conversion point (which results in training registrations)\nSocial Media (Twitter, LinkedIn, Facebook)"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#channels-for-attracting-users-ii",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#channels-for-attracting-users-ii",
    "title": "Impact of the Ontotext Training Program",
    "section": "5.2 Channels for Attracting Users II",
    "text": "5.2 Channels for Attracting Users II\n\nAds (Google, KD Nuggets, DB Engines)"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#conversions-to-opportunities",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#conversions-to-opportunities",
    "title": "Impact of the Ontotext Training Program",
    "section": "6.1 Conversions to Opportunities",
    "text": "6.1 Conversions to Opportunities\nCurrently, there are no formal open opportunities (closed won or closed lost) with participants from the training but we are in touch with several of them in relation to their ongoing projects, in which they implement GraphDB and/or some other relevant technology."
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#use-case-1-gregory-saumier-finch-culture-creates",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#use-case-1-gregory-saumier-finch-culture-creates",
    "title": "Impact of the Ontotext Training Program",
    "section": "6.2 Use Case 1: Gregory Saumier-Finch, Culture Creates",
    "text": "6.2 Use Case 1: Gregory Saumier-Finch, Culture Creates\n\nCulture Creates is a Canadian company that makes live events findable for voice powered search and AI powered virtual assistants, like Siri, Alexa and Google Assistant. It also wants to ensure that arts organizations will always be the digital authority of their own metadata.\nA PoC was presented earlier this year at a conference in Quebec City in Canada, focusing on Innovation in Culture. Part of the presentation was dedicated to showing how GraphDB works when filled with current performing arts events metadata. A couple of visualizations based on SPARQL queries were also generated.\nVideo (2:49): https://www.youtube.com/watch?v=WalOgD41kDE"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#use-case-2-adam-wyner-university-of-aberdeen",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#use-case-2-adam-wyner-university-of-aberdeen",
    "title": "Impact of the Ontotext Training Program",
    "section": "6.3 Use Case 2: Adam Wyner, University of Aberdeen",
    "text": "6.3 Use Case 2: Adam Wyner, University of Aberdeen\n\nAlready presented"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#andrea-mignone",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#andrea-mignone",
    "title": "Impact of the Ontotext Training Program",
    "section": "7.1 Andrea Mignone",
    "text": "7.1 Andrea Mignone"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#the-team",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#the-team",
    "title": "Impact of the Ontotext Training Program",
    "section": "8.1 The Team",
    "text": "8.1 The Team\n\nTrainings are multi-disciplinary projects\nThey unite efforts by several Ontotext teams\n\n\n\n\n\n\n\n\n\n\nICO\nSAS\nDMP\nMarketing\n\n\n\n\nVladimir Alexiev\nNeli Hateva\nRadostin Nanov\nIva Mechkunova\n\n\nIvelina Nikolova\nPetar Mitankin\nTeodor Todorov\nMilen Yankulov\n\n\nAlexander Popov\n\n\n\n\n\nBoyan Simeonov\n\n\n\n\n\nAndrey Tagarev\n\n\n\n\n\nPlamen Tarkalanov\n\n\n\n\n\nNikola Tulechki"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#with-the-special-participation-of",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#with-the-special-participation-of",
    "title": "Impact of the Ontotext Training Program",
    "section": "8.2 With the Special Participation of",
    "text": "8.2 With the Special Participation of\n\nVassil Momtchev\nAtanas Kiryakov"
  },
  {
    "objectID": "markdown/20180607-Training-OTTrainingImpact/Slides.html#the-new-training-master",
    "href": "markdown/20180607-Training-OTTrainingImpact/Slides.html#the-new-training-master",
    "title": "Impact of the Ontotext Training Program",
    "section": "8.3 The New Training Master",
    "text": "8.3 The New Training Master\n\nNikola Tulechki"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#factforge-data-integration",
    "href": "markdown/20180920-Datathon/Slides.html#factforge-data-integration",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "1 FactForge: Data Integration",
    "text": "1 FactForge: Data Integration\n\nDBpedia (the English version) 496M\nGeonames (all geographic features on Earth) 150M\nowl:sameAs links between DBpedia and Geonames 471K\nCompany registry data (GLEI) 3M\nPanama Papers DB (#LinkedLeaks) 20M\nOther datasets and ontologies: WordNet, WorldFacts, FIBO\nNews metadata (2000 articles/day enriched by NOW) 473M\nTotal size (1611M explicit + 328M inferred statements) 1939М"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#factforge-news-metadata",
    "href": "markdown/20180920-Datathon/Slides.html#factforge-news-metadata",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "2 FactForge: News Metadata",
    "text": "2 FactForge: News Metadata\n\nMetadata from Ontotext’s Dynamic Semantic Publishing platform\n\nNews stream from Google\nAutomatically generated as part of the NOW.ontotext.com semantic news showcase\n\nNews stream from Google since Feb 2015, about 50k news/month\n\nOver 1M news articles at present\n~70 tags (annotations) per news article\n\nTags link text mentions of concepts to the knowledge graph\n\nTechnically these are URIs for entities (people, organizations, locations, etc.) and key phrases"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#factforge-classes",
    "href": "markdown/20180920-Datathon/Slides.html#factforge-classes",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "3 FactForge: Classes",
    "text": "3 FactForge: Classes"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#factforge-organisations",
    "href": "markdown/20180920-Datathon/Slides.html#factforge-organisations",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "4 FactForge: Organisations",
    "text": "4 FactForge: Organisations"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#bottom-up-industry-classification",
    "href": "markdown/20180920-Datathon/Slides.html#bottom-up-industry-classification",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "5 Bottom-up Industry Classification",
    "text": "5 Bottom-up Industry Classification\n\nLeverage wikipedia manual classification\nNormalize and organize\n\nMerge and order to produce a hierarchy\n17361 industry tags with no clear connection\n9560 literals and 7801 IRIs\n\nThe result\n\n32 top-level industries\n240 industries total organized in multiple levels\ntag clusters give richness of expression"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#the-problem",
    "href": "markdown/20180920-Datathon/Slides.html#the-problem",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "6 The Problem",
    "text": "6 The Problem\n… as always- messy data.\n\nCompanies are sometimes incorrectly classified (Type I error)\nSome companies are not classified in all appropriate industries (Type II error)"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#the-task",
    "href": "markdown/20180920-Datathon/Slides.html#the-task",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "7 The Task",
    "text": "7 The Task\nDescribe and evaluate a technique for identifying both types of errors in the data."
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#the-data",
    "href": "markdown/20180920-Datathon/Slides.html#the-data",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "8 The Data",
    "text": "8 The Data"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#the-data-ii",
    "href": "markdown/20180920-Datathon/Slides.html#the-data-ii",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "9 The Data II",
    "text": "9 The Data II\n\nSimple csv dump\n\nContains all organisations\nIncludes several useful direct features\n\nname\ndescription\nwikipedia categories\nlocation\nindustries"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#the-data-iii",
    "href": "markdown/20180920-Datathon/Slides.html#the-data-iii",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "10 The Data III",
    "text": "10 The Data III\n\nDeep graph features\n\nNo dump as there are too many possibilities\nProvided are sample SPARQL queries to extract some promising features for each organisation\n\ndirect links to wikipedia articles\ndirect links from wikipedia articles\nindirect links through news mentions\nmapping from industries to lists of keywords\nrich geographical information (through geonames)\nparent/subsidiary relations\n\nMentors can provide assistance for modifying the queries or creating new ones for novel features"
  },
  {
    "objectID": "markdown/20180920-Datathon/Slides.html#the-data-iv",
    "href": "markdown/20180920-Datathon/Slides.html#the-data-iv",
    "title": "Ontotext Case: Automated Detection of Anomalous Industry Classification in Linked Data. @ Global Datathon 2018",
    "section": "11 The Data IV",
    "text": "11 The Data IV\n\nhttp://factforge.net/sparql"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#intro-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#intro-1",
    "title": "Merge requests in GitLab",
    "section": "1.1 Intro",
    "text": "1.1 Intro\n\nAllow to exchange changes made to source code\nCollaborate with other people on the same project\nRequest to merge one brach into another"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#benefits-of-using-gitlab-merge-requests-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#benefits-of-using-gitlab-merge-requests-1",
    "title": "Merge requests in GitLab",
    "section": "2.1 Benefits of using GitLab Merge requests",
    "text": "2.1 Benefits of using GitLab Merge requests\n\nComparison between changes in two branches\nReviews and discussions – proposed modifications inline\nLive preview of the changes when Review Apps configured for the project\nBuilds, tests and deployment in a per-branch basis with built-in GitLab CI/CD\nPrevent the MR from being merged before it’s ready with Work In Progress MRs"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#benefits-of-using-gitlab-merge-requests-2",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#benefits-of-using-gitlab-merge-requests-2",
    "title": "Merge requests in GitLab",
    "section": "2.2 Benefits of using GitLab Merge requests",
    "text": "2.2 Benefits of using GitLab Merge requests\n\nVisible deployment process through Pipeline Graphs\nAutomatically closure of issues that originated the implementation proposed in the MR\nConvenience by reassigning the assignee\nConvenience by assigning a milestone and keeping track of the development\nEasier organization of issues and MRs with labels"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#benefits-of-using-gitlab-merge-requests-3",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#benefits-of-using-gitlab-merge-requests-3",
    "title": "Merge requests in GitLab",
    "section": "2.3 Benefits of using GitLab Merge requests",
    "text": "2.3 Benefits of using GitLab Merge requests\n\nTime Estimation & Time Spent with Time Tracking\nResolve merge conflicts from the UI\nPossible Fast-Forward MRs\nSemi-Linear history MRs – another security layer for pipeline passing"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#benefits-of-using-gitlab-merge-requests-4",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#benefits-of-using-gitlab-merge-requests-4",
    "title": "Merge requests in GitLab",
    "section": "2.4 Benefits of using GitLab Merge requests",
    "text": "2.4 Benefits of using GitLab Merge requests\n\nCreation of new MRs by email\nPossible edit of the MR from maintainers"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#merge-requests-per-project-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#merge-requests-per-project-1",
    "title": "Merge requests in GitLab",
    "section": "3.1 Merge requests per project",
    "text": "3.1 Merge requests per project\n\nProject &gt; Merge Requests\nOpen/Merged/Closed Requests\n\n\nAn example of Project MRs"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#merge-requests-per-group-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#merge-requests-per-group-1",
    "title": "Merge requests in GitLab",
    "section": "4.1 Merge requests per group",
    "text": "4.1 Merge requests per group\n\nGroup &gt; Merge Requests\n\n\nAn example of Group MRs"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#removing-the-source-branch-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#removing-the-source-branch-1",
    "title": "Merge requests in GitLab",
    "section": "5.1 Removing the source branch",
    "text": "5.1 Removing the source branch\n\n“Remove source branch when merge request accepted” option on creation of a MR\nAlso visible in an existing one\nVisible only to master users\n\n\nAn example of removing source branch"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#discussions-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#discussions-1",
    "title": "Merge requests in GitLab",
    "section": "6.1 Discussions",
    "text": "6.1 Discussions\n\nComments at issues, MRs, snippets, commits, commit diffs\nResolvable discussions\n\n\nAn example of resolvable discussion"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#discussions-2",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#discussions-2",
    "title": "Merge requests in GitLab",
    "section": "6.2 Discussions",
    "text": "6.2 Discussions\n\nCommit discussions in the context of a MR"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#discussions-3",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#discussions-3",
    "title": "Merge requests in GitLab",
    "section": "6.3 Discussions",
    "text": "6.3 Discussions\n\nJumping between unresolved discussions\nMarking a comment or discussion as resolved\nMove all unresolved discussions in a merge request to an issue\nMoving a single discussion to a new issue"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#discussions-4",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#discussions-4",
    "title": "Merge requests in GitLab",
    "section": "6.4 Discussions",
    "text": "6.4 Discussions\n\nOnly allow merge requests to be merged if all discussions are resolved\nAutomatically resolve merge request diff discussions when they become outdated\nThreaded discussions\nImage discussions\nLock discussions"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#automatically-close-an-issue-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#automatically-close-an-issue-1",
    "title": "Merge requests in GitLab",
    "section": "7.1 Automatically close an issue",
    "text": "7.1 Automatically close an issue\n\nVia Merge Request\n\n\nClosing an issue\nFrom the Issue Board"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#labels-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#labels-1",
    "title": "Merge requests in GitLab",
    "section": "8.1 Labels",
    "text": "8.1 Labels\n\nAllow categorization of issues and MRs using discriptive titles\nProject and group labels\nIssues &gt; Labels"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#fast-forward-merge-requests-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#fast-forward-merge-requests-1",
    "title": "Merge requests in GitLab",
    "section": "9.1 Fast-Forward Merge requests",
    "text": "9.1 Fast-Forward Merge requests\n\nLinear Git history\nNo merge commits\nSettings → ‘Merge method’ → Fast-forward merge"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#semi-linear-history-merge-requests-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#semi-linear-history-merge-requests-1",
    "title": "Merge requests in GitLab",
    "section": "10.1 Semi-Linear history merge requests",
    "text": "10.1 Semi-Linear history merge requests\n\nMerge commit for every merge\nMerged only if FF possible\nEnsures success by pipeline passing\nMerge Requests: Merge method → Merge commit with semi-linear history"
  },
  {
    "objectID": "markdown/20180529-GitLab-MergeRequests/Slides.html#creation-of-new-merge-requests-by-email-1",
    "href": "markdown/20180529-GitLab-MergeRequests/Slides.html#creation-of-new-merge-requests-by-email-1",
    "title": "Merge requests in GitLab",
    "section": "11.1 Creation of new merge requests by email",
    "text": "11.1 Creation of new merge requests by email\n\nBy clicking on “Email a new merge request to this project” button\nThe subject – the source branch name\nThe message body – the MR description"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#about-ontotext-1",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#about-ontotext-1",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "1.1 About Ontotext",
    "text": "1.1 About Ontotext\n\nFounded 2000, part of Sirma Group (400 people, BSE:SKK, part of SOFIX), venture funding 2008\n65 people: 7 PhD, 30 MS, 20 BS, 6 university lecturers. Offices in Sofia, Varna, London\nCore part of Sirma Strategy 2022 with focus on cognitive computing\nWorking on: semantic technologies, semantic repositories, semantic text analysis, machine learning\nSemantic Graph Database: Ontotext GraphDB\nSemantic data integration and building of Knowledge Graphs\nSemantic text analysis: entity, concept, relation extraction, document classification\nRecommendations, sentiment analysis\nMachine learning: entity disambiguation, deep learning in graphs, etc"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#research-projects",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#research-projects",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "1.2 Research Projects",
    "text": "1.2 Research Projects"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#current-projects",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#current-projects",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "1.3 Current Projects:",
    "text": "1.3 Current Projects:\n\nEHRI2: European Holocaust Research Infrastructure (H2020 RI)\nEvala: Congnitive and Semantic Links Analysis and Media Evaluation Platform (EuroStars)\neuBusinessGraph: Innovative Data Products and Services for Company Data (H2020 BigData Experimentation)\nCOMPACT: From Research Through Policy on Social Media and Convergence (H2020 CSA)\nBigDataGrapes: BigData to Enable Global Disruption of the Grapevine-Powered Industries (H2020 BigData Research)\nCIMA: Company Intelligent Matching and Linking (BG OPC ISIS)\nTRR: Tracking of Research Results for EC framework programs (EC Tender)"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#research-and-innovation-awards",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#research-and-innovation-awards",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "1.4 Research and Innovation Awards",
    "text": "1.4 Research and Innovation Awards\nArguably, Ontotext is the most innovative Bulgarian software company.\n\nInnovative Enterprise of the Year 2017\nEU Innovation Radar Prize 2016 nomination\nBAIT Business Innovation Award 2014\nInnovative Enterprise of the Year 2014\nWashington Post “Destination Innovation” Competition 2014 Award\nPythagoras Award 2010 for most successful company in EU FP6 projects\n\nWe have more EU research projects than some universities combined"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#industries-and-clients",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#industries-and-clients",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "1.5 Industries and Clients",
    "text": "1.5 Industries and Clients\n80% of our sales are in the UK and US\n\nMedia: BBC, UK Press Association, NL Press Association (NDP)…\nFinancial Info: S&P Global Platts, Euromoney, Financial Times, Nikkei…\nSTEM Publishing: IET, Oxford University Press, Wiley, Elsevier, Springer Nature…\nLife Science: AstraZeneca, Novartis…\nGovernment: UK Parliament, The National Archives, Natural Resources Canada…\nCultural Heritage and Digital Humanities"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#about-me",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#about-me",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "1.6 About Me",
    "text": "1.6 About Me\n\n2009 - MS in Linguistics at Toulouse Federal University\n2010-2015 PhD in Natural Language Processing at Toulouse Federal University\n\nProcessing of avaiation incident and accident reports.\nData from Air France, DGAC and EASA\n\n2017 Semantic data consulting at Ontotext"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#context",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#context",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.1 Context",
    "text": "2.1 Context\n\nThe EHRI project\n\nCore consortium of more than twenty organisations – research institutions, libraries, archives, museums and memorial sites.\nMission is to support the wider Holocaust research community by building a digital infrastructure and facilitating human networks\n\nPerson networks case\n\n5Mi Records of Holocaust survivors and victims (HSV)\nProducing and publishing a coherent dataset capable of supporting quantitative research approaches."
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#the-data-problem",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#the-data-problem",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.2 The Data problem",
    "text": "2.2 The Data problem\n\nTranscripts of lists of names aggreted and managed by USHMM\n\nover 40K sources (12K digitalized)\nTotal 5M records, one name per record + information depending on the source\n\nThe data is in the form of a digital archive\n\nExcellent for finding information about individuals\nMaximum of information from the various sources is conserved R\n\nImpossible to exploit without a per record human interpretative effort\n\nNo record deduplication\nAmbiguous property names\nImportant information raw in text fields"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#example-sources",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#example-sources",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.3 Example sources",
    "text": "2.3 Example sources\n\n243964 Lodz-Names: A Record of the 240,000 Inhabitants of the Łódź Ghetto\n3261 Seznam osob popravených na základě rozsudku stanného, lidového a zvlastního soudu od 27.září 1941 a osob, jimž bylo zabaveno jmění podle těchto nařízení\n3260 Jewish Families Deported from Dorohoi to Transnistria\n3256 List of The Jews of Dés (Dej) Used in the Ghettoization of May 3-10, 1944\n3180 [Auschwitz to Buchenwald Transport, January 26, 1945]\n1525 [Data file of Jewish property owners in Panevezys, Lithuania from the Panevezys County Archive]\n1522 Franzstrasse Nr. 38\n740 [Name data from a list of Jews who were released from Bergen-Belsen and arrived in Switzerland in December 1944]\n501 Survivor children airlifted from Theresienstadt “camp-ghetto” to England post-war"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#data-integration-task",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#data-integration-task",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.4 Data integration task",
    "text": "2.4 Data integration task\n\nRecord deduplication - identical/similar sounding names and close birth dates\nReconstructing family relationships\nLinking people-clusters to events"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#linking-and-deduplication",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#linking-and-deduplication",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.5 Linking and deduplication",
    "text": "2.5 Linking and deduplication"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#inferring-family-relations",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#inferring-family-relations",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.6 Inferring Family relations",
    "text": "2.6 Inferring Family relations\n\nExplicit family relations for 142K pairs (manually constructed by historians)\nMany more in the data\n\nFamilies referenced by common number\nPeople listed with their address\nRelationships between people present (in all european languages)"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#peson-networks-model",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#peson-networks-model",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.7 Peson networks model",
    "text": "2.7 Peson networks model"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#agrelon-ontology",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#agrelon-ontology",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.8 AgRelOn Ontology",
    "text": "2.8 AgRelOn Ontology"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#results",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#results",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.9 Results",
    "text": "2.9 Results\n\nFrom a source of 104K explicit relations inference of 10K more links between previously unconnected nodes (10% expansion) in the explict data\n\nMore possible (e.g cousins) if we extend AgRelOn even further\n\nUse of the AgRelOn abstraction hierarchy (agrelon:hasRelative agrelon:RelatedAgent) and basis for bootstraping even more relations based on fragmented information from the original sources\n\nInfer hasRelative based on available information (shared address, family number)\nUse “relationshipToHead” property to further refine the relationship type\n\nTotal inferred relations\n\n104M agrelon:relatedAgent\n5.7M agrelon:HasRelative\n76K agrelon:hasOffspring\netc…"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#constructing-of-personal-events",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#constructing-of-personal-events",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.10 Constructing of personal events",
    "text": "2.10 Constructing of personal events\n(Work in progress)\n\nConstruct personal events combining data from the source and data from the record.\nUse CIDOC-CRM ontolgy (very complex)\nPerform location matching\n\nGeonames for known locations\nCustom lists for historic locations (camps, ghettos etc)\nLarge number of completely unknown locations?\n\nConnect people to temporal intervals and perform temporal reasoning to construct personal trajectories"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#cidoc-crm-temporal-entity-model",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#cidoc-crm-temporal-entity-model",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "2.11 CIDOC-CRM temporal entity model",
    "text": "2.11 CIDOC-CRM temporal entity model"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#context-and-scope",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#context-and-scope",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.1 Context and scope",
    "text": "3.1 Context and scope\nTRR Tracking of Research Results EC want to better track impact of framework research programs\nPilot project - scope FR7-SP1 (8000) eu funded projects\nOntotexts tasks:\n\nSemantic Data integration from various graphs of science\n\nPublications\nResearchers\nOrganisations\nPatents\nDatasets\n\nData management and hosting\nWork on success indicators\nBuild and host integrated knowledge graph\nNLP on project reports\nWeb Scraping and crawling?"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#potential-datasources-for-a-aggregated-knowledge-graph",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#potential-datasources-for-a-aggregated-knowledge-graph",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.2 Potential Datasources for a aggregated knowledge graph",
    "text": "3.2 Potential Datasources for a aggregated knowledge graph\n\nOpenAIRE (Solid links to EC projects, quantity)\nCrossRef (issuers of DOI)\nOpenCitation (OCC and COCI)\nScopus\nWeb of Science\nMicrosoft Academic Graph (solid data on affiliations)\nSemantic Scholar\nArnet Miner\nLens.org (Patents)\nORCID: researchers, CVs (education and employment affiliations), publications\nWikidata, WikiCite, Scholia\nDigital Science: Dimensions, UberResearch\nWizdom.ai\nSpringer Nature Science Graph\nDBLP\n(Aggregation) Open Academic Graph = MAG & Arnet Miner, by paper title, authors, year\n(Aggregation) DOIboost = MAG & CrossRef & Unpaywall, by paper DOI then author names"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#success-indicators-1",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#success-indicators-1",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.3 Success indicators (1)",
    "text": "3.3 Success indicators (1)\n\nNumber of Nobel prize winners among FP7 researchers\nNumber of winners of other prestigious international prizes (Fields Medal, Lasker Award, etc.)\nNumber of winners of prestigious national scientific prizes\nNumber of product, service, process innovations created\nImproved commercialisation/valorisation perspectives (number of projects/technologies attracting interest from industry, evidence of licensing, additional investment attracted, etc.)\nNumber of dissemination events (conferences, workshops, etc.), of which key/major events involving policymakers\nProject websites (working/not working)\nPresence of social media profiles\nData management plans\nEvidence of data shared\nLeveraged private and public investment in R&I (no. Of additional projects/grants; total funding received in euros)\nAdditionally leveraged funding by SMEs/spin-offs/other organisations\nNumber of researchers moving to another country/sector/discipline (for key researchers)"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#success-indicators-2",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#success-indicators-2",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.4 Success indicators (2)",
    "text": "3.4 Success indicators (2)\n\nGrowth, jobs, industrial partnership, innovation clusters, access to new markets, commercialisation/potential for commercialisation, partnerships\nEffects of FP7 participation on economic performance (matched-pair approach)\nNumber of new companies/spin-offs created\nPerformance of newly created SMEs/spin-offs (size, turnover, profitability, etc.)\nImproved health and quality of life, working life, living environment\nImproved life expectancy\nEvidence of uptake of FP7 research in clinical guidelines/clinical trials involving humans (optional)\nImproved environmental performance, reduced greenhouse gas emission, reduced air pollution, improved water quality, better mitigated environmental risks, etc.\nEconomic impacts, economic benefits, improved efficiency (in euros)\nImproved competitiveness relative to the US, Japan, China, other countries\nSocial and cultural impacts (various, as per annex 13)\nImproved convergence between EU-15 and EU-13\nInfluence on policy making/political impact"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#indicator-14-scientific-awards",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#indicator-14-scientific-awards",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.5 Indicator 14 Scientific Awards",
    "text": "3.5 Indicator 14 Scientific Awards\nGathering awards from Wikidata\n\nWikidata had concentrated structured data about 1224 “science awards”\nSome awards did not have the appropriate Wikidata type (ex. “award” instead of “science awards”).\nUsing the WP Category system we were able to add the correct type and extend the list to 1815 awards."
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#award-winners-in-wikidata",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#award-winners-in-wikidata",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.6 Award winners in WikiData",
    "text": "3.6 Award winners in WikiData\nWikidata also has info on award winners (27443 “wins” of 983 awards)"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#extending-wikidata-award-winners-from-wikipedia-categories",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#extending-wikidata-award-winners-from-wikipedia-categories",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.7 Extending wikidata award winners from Wikipedia categories",
    "text": "3.7 Extending wikidata award winners from Wikipedia categories\n\nAward winners are often listed in Wikipedia using Wikipedia Categories\nCategories are not the same accross languages\nWikidata has a property linking the award entiy to the wikipedia category\nPetScan extracts lists of objects wikidata entitites from wikipedia categories\n\nResult: 2367 new award winners in Wikidata."
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#petscan-interface",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#petscan-interface",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.8 Petscan Interface",
    "text": "3.8 Petscan Interface"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#adding-weight-to-awards",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#adding-weight-to-awards",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "3.9 Adding weight to awards",
    "text": "3.9 Adding weight to awards\n\nThe IREG Observatory’s list contains the most prestigious awards ranked by reputation score\nThe PDF file needs has been converted into a table\nThe data has been matched to the list of awards from Wikidata\nThe reputation score has been added to Wikidata"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#context-and-scope-1",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#context-and-scope-1",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "4.1 Context and scope",
    "text": "4.1 Context and scope\n(Open Source Intelligence) OSINT in the Banking sector A lot of cybersecurity related data is publicly available\n\nDedicated data model (STIX)\nData providors - MITRE corp (WIKI and STIX)\nMISP galaxy - Github repo with fresh data"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#unstructured-data",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#unstructured-data",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "4.2 Unstructured data",
    "text": "4.2 Unstructured data\n\nCybersec reports in plain text\nSecurity corporations (Symantec, Kaspersky), Blogs etc.."
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#cyberthreat-report-screenening",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#cyberthreat-report-screenening",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "4.3 Cyberthreat report screenening",
    "text": "4.3 Cyberthreat report screenening\n\nGoal1: Integrate public data sources in a client ontology and build a knowledge graph\nGoal2: Automatically extract instance data from raw text and further populate the knowledge graph\n\nMain difficulty: Entities manifest at different levels:\nLocal Named entities (apt28, group123, rokrat) - trivial to annotate automatically\nComplex entities such as techniques and tactics are more complicated\n\n\nThis vulnerability is a use after free that allows Remote Code Execute T1203 Exploitation for Client Execution"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#manual-annotation-and-textual-classifcation-task",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#manual-annotation-and-textual-classifcation-task",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "4.4 Manual Annotation and textual classifcation task",
    "text": "4.4 Manual Annotation and textual classifcation task\n\nManually annotate documents using Ontotext’s annotation tool\n\n\n\nBuild a textual classification pipeline that predicts if a sentence is a mention of a “Technique” or “Tactic” class."
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#ontotext-factforge",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#ontotext-factforge",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "6.1 Ontotext FactForge",
    "text": "6.1 Ontotext FactForge\nFactForge is a hub for open data and news about people, organizations and locations. Contains over 1B facts Showcasing GraphDB and Semantic Technologies\nhttp://factforge.net/"
  },
  {
    "objectID": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#graphdb",
    "href": "markdown/20181031-SemanticTechnologiesAtOnto-UniYork/Slides.html#graphdb",
    "title": "Semantic technologies in practice: Designing, building and exploiting knowledge graphs at Ontotext",
    "section": "6.2 GraphDB",
    "text": "6.2 GraphDB\n\nFast triplestore 100% W3C compliant\nFree version with very few limitations\nExcellent SPARQL editor\nExcellent ETL tools (OpenRefine integration)\nFulltext search integration (Lucene, SOLR, Elastic)\nVery well documented\nMany more features\nAcademic cooperation program\n\nhttps://www.ontotext.com/products/graphdb/editions/\n\n\n\n@ UniYork"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#introduction",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#introduction",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "0.1 Introduction",
    "text": "0.1 Introduction\n\nSemantic Data Integration is a lot more than Ontology Engineering:\n\nDataset research\nData analysis\nData cleaning\nSemantic model: examples, shapes, documentation\nOntology engineering\nData mapping/conversion (ETL)\nInstance matching/reconciliation\nData fusion/harmonization\nSemantic text/metadata enrichment\nData enrichment, inference, aggregation\nSample queries\nSemantic search, apps, visualizations"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#how-does-this-differ-from-data-warehousing",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#how-does-this-differ-from-data-warehousing",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "0.2 How Does This Differ from Data Warehousing?",
    "text": "0.2 How Does This Differ from Data Warehousing?\n\nSemantic databases (Knowledge Bases or Knowledge Graphs) are self-describing\nData warehousing usually focuses on statistical data (OLAP)\nKGs can represent OLAP using the W3C Cube ontology, but can also represent any other kind of data\nThere are vast LOD datasets that can be utilized in building KGs\nEveryone seems to be building a KG!"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#example",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#example",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "0.3 Example",
    "text": "0.3 Example\nGoogle KG: Entity Pages, Disambiguation"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#competence-questions",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#competence-questions",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "0.4 Competence Questions",
    "text": "0.4 Competence Questions\n\nBefore developing applications, one better develop business requirements\nBefore procuring/integrating data, one better develop competence questions\nThese are sample questions that the KG should be able to answer\nThey should lead both dataset research and semantic modeling"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#how-to-find-datasets",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#how-to-find-datasets",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "1.1 How to Find Datasets?",
    "text": "1.1 How to Find Datasets?\n\nWikidata’s external-id props are an excellent source (over 3700)\nA lot of them have corresponding Mix-n-Match catalog\n\nA lot are potentially applicable to GLAM, eg Authority control for people 510, Identifier 196, Authority control 102, Authority control for artists 59, Cultural heritage identification 34, etc\n\nWikipedia categories and Related links\nhttps://datahub.io and https://old.datahub.io\nhttp://lod-cloud.net"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#lod-cloud",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#lod-cloud",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "1.2 LOD Cloud",
    "text": "1.2 LOD Cloud\nThe Linked Open Data (LOD) Cloud contained 28 datasets in 2007"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#datasets-in-2009",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#datasets-in-2009",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "1.3 … 89 datasets in 2009 …",
    "text": "1.3 … 89 datasets in 2009 …"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#datasets-in-2011",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#datasets-in-2011",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "1.4 … 295 datasets in 2011 …",
    "text": "1.4 … 295 datasets in 2011 …"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#datasets-in-2014",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#datasets-in-2014",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "1.5 … 570 datasets in 2014 …",
    "text": "1.5 … 570 datasets in 2014 …"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#datasets-today",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#datasets-today",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "1.6 … 1234 datasets today!",
    "text": "1.6 … 1234 datasets today!\n\n16136 links between datasets, 30B triples"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#wikidata",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#wikidata",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "1.7 Wikidata",
    "text": "1.7 Wikidata\nNumber of Creative Works and Cultural Institutions in Wikidata:"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#finding-data",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#finding-data",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "1.8 Finding Data",
    "text": "1.8 Finding Data\n\nBy Example:\n\nEg to find computer science awards, get a famous computer scientist (eg Tim Berners-Lee) and explore his awards\nEg to find artist biographic info, get a well-known artist (eg Emily Carr), find mentions of her on the web, list the ones that provide good biographic text\n\nKnowledge and experience helps\n\nKeep abreast of LOD developments in your domain\nRead papers, especially in the SWJ http://www.semantic-web-journal.net/accepted-datasets"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#scope",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#scope",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "2.1 Scope",
    "text": "2.1 Scope\n\nFeasibility estimations confronting the data with the use cases.\nFamiliarisation with the data\n\nSize and complexity estimations of the data are performed\nThe data is comprehensively understood\nExceptional values are extracted and analyzed\n\nCardinalities are extracted and analyzed\nThe tools for the later phases are chosen\nGeneral feasibility is estimated\nThe groundwork for the mapping component of ETL is laid down"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#key-value-analysis",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#key-value-analysis",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "2.2 Key Value Analysis",
    "text": "2.2 Key Value Analysis\n\nKey values that often drive the mapping. Key-values could be mapped to:\n\nIndividual (eg skos:Concept)\nClass\nProperty\nor can even dictate a mapping decision, eg one mapping branch for Persons, another for Organizations"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#key-value-example",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#key-value-example",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "2.3 Key Value Example",
    "text": "2.3 Key Value Example\nFrоm Getty LOD - “Excel-driven Ontology Generation™”\n ref"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#data-coverage",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#data-coverage",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "2.4 Data Coverage",
    "text": "2.4 Data Coverage\nExample: PubMed Field Statistics"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#data-quality",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#data-quality",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "2.5 Data Quality",
    "text": "2.5 Data Quality\n\nCoverage assessment dictates what is worth converting\nQuality assessment drives data cleaning needs and decisions"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#scope-1",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#scope-1",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "3.1 Scope",
    "text": "3.1 Scope\n\nCreate a data model for the domain of interest\nFind existing relevant ontologies to use\nAdd custom classes and properties as needed (Ontology Engineering)\nDocument the model comprehensively: describe modeling patterns, justify decisions\nDocument in machine-readable way using RDF Shapes (SHACL or ShEx)\nMake examples that can drive (generate) other artifacts, eg example diagrams, shapes"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#url-design",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#url-design",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "3.2 URL Design",
    "text": "3.2 URL Design\n\n“URL Design” is something simple yet fundamental to RDF and LOD.\nIt’s a fundamental part of TimBL’s 5-Star Linked Data principles: CoolUri’s don’t change, Cool URIs for the Semantic Web\nWell-designed URLs enable highly distributed ETL development and execution\nExperience shows that leaving URL design to ETL devs is not a good idea: unspecified URLs cause disconnected data\nPlatts URL Design (internal document, could be shared)\nGetty doc on URLs"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#existing-or-new-ontology",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#existing-or-new-ontology",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "3.3 Existing or New Ontology?",
    "text": "3.3 Existing or New Ontology?\nPros:\n\nReuse as much as possible\nThis will save you time, and will make your data more easily reusable\nSearch for ontologies: Linked Open Vocabularies\n\nCons:\n\nMultiple namespaces make data production/consumption a bit harder\nSchema.org is the ultimate “chauvinistic” example: single namespace, and even extensions (eg GoodRelations or SchemaBibEx) land in the same namespace.\n\nI guess webmasters like the simplicity (and still often get it wrong ;-)\n\nDon’t reuse a complex ontology for a single term (heavy ontology baggage)\nConsider reusing ontology terms, but not necessarily loading the ontology\n\nExample: every dct: property is a subprop of dc:, and such inference may be useless to you"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#ontology-methodologies",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#ontology-methodologies",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "3.4 Ontology Methodologies",
    "text": "3.4 Ontology Methodologies\nHow to do ontology engineering?\n\nAvoid it if you can (i.e. reuse ;-)\nCompetence Questions !\nMethods such as DILIGENT, METHONTOLOGY, NeON Methodology, ROO Kanga, SAMOD (Simplified Agile Methodology), HCOME (Human-centered ontology method), Aspect OntoMaven (Aspect-Oriented Ontology Development), IDEF5, ONTOCOM (cost estimation)\nOntology Design Patterns: typical situations. Composable!\nTop-level ontologies: BFO, CCO, DOL/DOLCE, SUMO, UFO, Proton…\n\nFor cultural heritage: CIDOC CRM, ConML/CHARM"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#scope-2",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#scope-2",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "4.1 Scope",
    "text": "4.1 Scope\n\nTransformation and homogenization of data sources into the target format, in order to populate the semantic model with instances\nImportant elements:\n\nChoice of tools in accordance with the need and requirements\nMaintainability of the solution\nReproducibility / exportability / portability\nData cleaning\n\nOther Considerations:\n\nformats\nsize scale (tools parse in memory)\nconsistency with existing conventions (project, sector)"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#example-1",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#example-1",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "4.2 Example",
    "text": "4.2 Example\n\nOnto ETL tools evaluation"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#rdf-shapes",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#rdf-shapes",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "5.1 RDF Shapes",
    "text": "5.1 RDF Shapes\nTODO links\n\nShEx: W3C community spec. Pros: much briefer (compact, JSON and RDF representations), allows recursive data models, flexible focus nodes (shape map).\nSHACL: W3C standard. SHACL-core and SHACL-standard. Advanced Features is a community spec. Pro: standardizes validation results\nValidating RDF book (reviewed by Ontotext)\nImplementations at Validating RDF wiki): summarized at next slides, but see the link for more details!"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#shex-implementations",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#shex-implementations",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "5.2 ShEx Implementations",
    "text": "5.2 ShEx Implementations\n\n\n\nname\nlanguage\nplayground, source, distribution\n\n\n\n\nshex.js\njs\nhttp://rawgit.com/shexSpec/shex.js/master/doc/shex-simple.html, https://github.com/shexSpec/shex.js/\n\n\nShEx NPM\njs\nhttps://www.npmjs.com/package/shex\n\n\nShEx-validator\njs\nhttps://github.com/HW-SWeL/ShEx-validator\n\n\nValidata\njs\nhttp://hw-swel.github.io/Validata/, https://www.w3.org/2015/03/ShExValidata/, https://github.com/HW-SWeL/Validata\n\n\nShExJava\njava\nhttp://shexjava.lille.inria.fr/, https://github.com/iovka/shex-java, https://gforge.inria.fr/projects/shex-impl/\n\n\nRDFShape, ShaclEx\nscala\nhttp://rdfshape.weso.es/, http://shaclex.herokuapp.com/, https://github.com/labra/rdfshape, https://github.com/labra/shaclex\n\n\nTrucHLe\nscala\nhttps://github.com/TrucHLe/SHACL\n\n\nPyShEx\npython\nhttps://github.com/hsolbrig/PyShEx\n\n\nshex.rb\nruby\nhttps://github.com/ruby-rdf/shex\n\n\nShExkell\nhaskell\nhttps://github.com/weso/shexkell"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#shacl-implementations",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#shacl-implementations",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "5.3 SHACL Implementations",
    "text": "5.3 SHACL Implementations\n\n\n\nname\nlanguage\nplayground, source,distribution\n\n\n\n\nSHACL API\njava\nhttps://github.com/TopQuadrant/shacl\n\n\nSHACL rdf4\njava\nhttps://github.com/eclipse/rdf4j-storage\n\n\nSHACL batch\njava\nhttps://github.com/PaulZH/shacl-batch-validator\n\n\nELI-validator\njava\nhttp://publications.europa.eu/eli-validator/home, http://labs.sparna.fr/eli-validator/,\n\n\nOSLO Validator\njava\nhttps://data.vlaanderen.be/shacl-validator/, https://github.com/pwc-technology-be/OSLO2Validator, https://github.com/Informatievlaanderen/OSLO-Validator\n\n\nshacl-runner\nscala\nhttps://github.com/balhoff/shacl-runner\n\n\nSTTL SHACL\njava\nhttp://corese.inria.fr/, http://ns.inria.fr/sparql-template\n\n\nNetage SHACL\njava\n\n\n\nSHACL JS\njs\nhttp://shacl.org/playground/, https://github.com/TopQuadrant/shacl-js\n\n\nSHACL-Check\njs\nhttps://github.com/linkeddata/shacl-check\n\n\nRDFShape, ShaclEx\nscala\nhttp://rdfshape.weso.es/, http://shaclex.herokuapp.com/, https://github.com/labra/rdfshape, https://github.com/labra/shaclex\n\n\npySHACL\npython\nhttps://github.com/CSIRO-enviro-informatics/pyshacl-webservice, https://github.com/RDFLib/pySHACL\n\n\nRDFUnit\njava\nhttps://github.com/AKSW/RDFUnit/\n\n\nalt SHACL\npython\nhttps://github.com/pfps/shacl"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#custom-test-suites",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#custom-test-suites",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "5.4 Custom Test Suites",
    "text": "5.4 Custom Test Suites\n\nRDFUnit (source, demo): sources custom patterns, OWL, OCLS shapes, DC Application Profiles, SHACL\nOnly SPARQL queries\n\nnegative examples\n\nSPARQL queries and example output\n\nCompares output of a query to the desired output\nCould test data and/or the queries themselves\n\nDomain Specific-Validation\n\nEg for SKOS: qSKOS, Sparna SKOS Tester"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#scope-3",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#scope-3",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "6.1 Scope",
    "text": "6.1 Scope\nSemantic enrichment is the adding of value to a dataset by increasing the amount of queryable information it contains and/or decreasing the data’s noisiness. This is done in several ways:\n\nInference and link discovery\nThesaurus harmonisation\nEntity mining\nInstance matching and deduplication.\nData fusion"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#inference-and-link-discovery",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#inference-and-link-discovery",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "6.2 Inference and link discovery",
    "text": "6.2 Inference and link discovery\n\nInference : Attributes and relations are added based on rules.\nLink discovery. The structure and redundancies of the graph are exploited in order to discover new relations between entities (graph based ML)\n\nSubgraph similiarity to infer new links\ne.g Facebook friend recommendations\ne.g Amazon product recommendations"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#thesaurus-harmonisation",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#thesaurus-harmonisation",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "6.3 Thesaurus harmonisation",
    "text": "6.3 Thesaurus harmonisation"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#entity-mining.",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#entity-mining.",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "6.4 Entity mining.",
    "text": "6.4 Entity mining.\n\nUnstructured data (text, images) is processed in order to extract novel entities and relations and add them to the dataset.\nContent classification\n\nAttribution of categories to text, images or sound clips\n\nStatistical methods\ne.g e-mail filters\n\nNLP Named entity recognition (NER)\n\nOntotext NOW and TAG,\nGoogle NLP, etc\n\nRelation extraction from text\n\nNER + relations between entities"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#data-fusion.",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#data-fusion.",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "6.5 Data fusion.",
    "text": "6.5 Data fusion.\nRedundant data is deduplicated and fused to produce a single master dataset without conflicts.  selection of representative single fields (eg logo), * accumulation of multiple fields (eg names, transactions), * aggregation of summary fields (eg count or total amount)"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#matching",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#matching",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "6.6 Matching",
    "text": "6.6 Matching\n\nCritical problem in data cleaning and integration\nOverlapping instances across multiple datasets (client only or client and LOD) are matched and the sum of their attributes across datasets become available for querying.\nEntity matching (EM) finds data instances that refer to the same real-world entity\nWe focus on EM as a process of transforming a string to a thing based on the provided semantic context"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#basic-reconciliation",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#basic-reconciliation",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "6.7 Basic Reconciliation",
    "text": "6.7 Basic Reconciliation\n\nFuzzy name matching\nSimple additional features (e.g. exact string matches, differences in numbers)\nOut-of-the-box match scoring & available recon services\n\nOpenrefine, Ontorefine\nwikidata recon service\nreconcile-csv - build-your-own\n## Advanced Reconciliation\n\nCustom field parsing and normalization - additional parsing rules (acronyms, titles, dates etc)\nComplex additional features\n\ntext analysis\nhierarchical features\ngeographical features\nnetwork topology\n\nCustom match scoring (possibly deep learning) e.g deep siamese text similarity"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#scope-4",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#scope-4",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "8.1 Scope",
    "text": "8.1 Scope\n\nData Diagrams\nDetailed description of both new ontology terms (classes and properties) and reused ones (describing the specific use in our application profile).\nReference documentation\n\nGenerated by an ontology documentation tool\n\nHand written comprehensive doc\n\nSemantic publishing of model\n\nSample Queries"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#sample-queries",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#sample-queries",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "8.2 Sample queries",
    "text": "8.2 Sample queries\n\nVery handy way to augment the documentation\n\nCan be used by a new user to get a feel of the data\nHighly informative when combined with a short description\nStem out of competence questions\nCan be used for testing purposes\n\nEg GVP sample queries"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#semantic-search",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#semantic-search",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "9.1 Semantic Search",
    "text": "9.1 Semantic Search\n\nSearch for concepts rather than strings TODO nice example"
  },
  {
    "objectID": "markdown/20190311-LDLifeCycle/Slides.html#visualizations",
    "href": "markdown/20190311-LDLifeCycle/Slides.html#visualizations",
    "title": "Semantic Data Integration and the Linked Data Lifecycle",
    "section": "9.2 Visualizations",
    "text": "9.2 Visualizations\n\nGDB Visual Graph\nWikidata Viz page\nNeo4j Graph Database Platform Graph V-Day recap"
  }
]